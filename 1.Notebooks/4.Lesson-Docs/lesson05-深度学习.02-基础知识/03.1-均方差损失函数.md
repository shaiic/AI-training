Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

## 3.1 均方差函数

MSE - Mean Square Error。

该函数就是最直观的一个损失函数了，计算预测值和真实值之间的欧式距离。预测值和真实值越接近，两者的均方差就越小。

**均方差函数常用于线性回归(linear regression)，即函数拟合(function fitting)**。

#### 公式

$$
J(w,b)=\frac{1}{2m} \sum_{i=1}^m (a_i-y_i)^2
$$

### 3.1.1 工作原理

要想得到预测值a与真实值y的差距，最朴素的想法就是用$Error=a_i-y_i$。

对于单个样本来说，这样做没问题，但是多个样本累计时，$a_i-y_i$有可能有正有负，误差求和时就会导致相互抵消，从而失去价值。所以有了绝对值差的想法，即$Error=|a_i-y_i|$。

假设有三个样本的标签值是$y=[1,1,1]$：

|样本标签值|样本预测值|绝对值损失函数|均方差损失函数|
|------|------|------|------|
|$[1,1,1]$|$[1,2,3]$|$(1-1)+(2-1)+(3-1)=3$|$(1-1)^2+(2-1)^2+(3-1)^2=5$|
|$[1,1,1]$|$[1,3,3]$|$(1-1)+(3-1)+(3-1)=4$|$(1-1)^2+(3-1)^2+(3-1)^2=8$|
|||4/3=1.33|8/5=1.6|

可以看到5比3已经大了很多，8比4大了一倍，而8比5也放大了某个样本的局部损失对全局带来的影响，用不通俗的语言说，就是“对某些偏离大的样本比较敏感”，从而引起监督训练过程的足够重视，以便差异化回传的误差。

### 3.1.2 实际案例

假设有一组数据如下，我们想找到一条拟合的直线：

<img src="..\Images\3\mse1.png"/>

下面四张图，前三张显示了一个逐渐找到最佳拟合直线的过程。
- 第一张，用均方差函数计算得到Loss=0.5559
- 第二张，直线向上平移一些，误差计算Loss=0.1651，比图一的误差小很多
- 第三张，又向上平移了一些，误差计算Loss=0.02441，此后还可以继续尝试平移（改变b值）或者变换角度（改变w值），得到更小的Loss值
- 第四张，偏离了最佳位置，误差值Loss=0.1336，这种情况，算法会让尝试方向反向向下

<img src="..\Images\3\mse2.png"/>

我们把四张图叠加在一起看一下，绿色的线是第三张图Loss值最小的情况。

<img src="..\Images\3\mse3.png"/>

比较第二张和第四张图，由于均方差的Loss值都是正值，如何判断是向上移动还是向下移动呢？

在实际的训练过程中，是没有必要计算Loss值的，因为Loss值会体现在反向传播的过程中。我们来看看均方差函数的导数：

$$
\frac{\partial{J}}{\partial{a_i}} = a_i-y_i
$$

虽然$(a_i-y_i)^2$永远是正数，但是$a_i-y_i$却可以是正数（直线在点下方时）或者负数（直线在点上方时），这个正数或者负数被反向传播回到前面的计算过程中，就会引导训练过程朝正确的方向尝试。

在上面的例子中，我们有两个变量，一个w，一个b，这两个值的变化都会影响最终的Loss值的。

我们假设该拟合直线的方程是y=3x+1，当我们固定w=3，把b值从0到2变化时，看看Loss值的变化：

<img src="../Images/3/LossWithB.png"/>

我们假设该拟合直线的方程是y=3x+1，当我们固定b=1，把w值从2到4变化时，看看Loss值的变化：

<img src="../Images/3/LossWithW.png"/>


【课堂练习：以y=3x+1为基准函数，用Python代码实现当w,b变化时，计算损失函数的过程，画出上面两张图】

其中w的变化可以是[2,4]，b的变化可以是[0,2]，取50个点。

### 3.1.3 损失函数的可视化

#### 损失函数值的3D示意图

横坐标为w，纵坐标为b，二者的组合会形成一个损失函数值，用三维图的高度来表示，最后形成一个碗状。该三维图到底面上的投影与下面的2D示意图类似。

<img src="../Images/3/lossfunction3d.png"/>

#### 损失函数值的2D示意图

横坐标为w，纵坐标为b，二者的组合会计算出一个损失函数值，存放在矩阵中，最后把矩阵中相近的损失函数值的连线会形成椭圆。

<img src="../Images/3/lossfunction2d.png"/>

#### 思考题

- 问题1：这幅图如何画出来？
- 问题2：为什么是椭圆而不是圆？
- 问题3：为什么中心是个椭圆区域而不是一个点？

代码位置：ch03, Level1
