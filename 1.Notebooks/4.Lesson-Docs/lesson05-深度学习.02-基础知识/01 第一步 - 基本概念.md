Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# <center>第一步</center>

# <center>基本概念</center>

## 摘要

在这一步中，我们将针对零基础的小白们，用通俗易懂的语言，讲述神经网络的基本概念。

首先会讲解一下神经网络基本的训练和工作原理，因为基本上各种教程里都没有提到这一点，以至于笔者在刚开始学习神经网络时一头雾水，不得要领，不知从何处开始下手。

后面接的是导数公式和反向传播公式，包括矩阵求导，这一部分可以大概浏览一下，主要的目的是备查，在自己推导反向公式时可以参考。

然后是反向传播和梯度下降，我们先从简单的线性方式说起（只有加法和乘法），而且用代入数值的方式来消除对公式的恐惧心理。然后会说到分层的复杂（非线性）函数的反向传播，同样用数值代入方式手推反向过程。

梯度下降是神经网络的基本学习方法，我们会用单变量和双变量两种方式说明，配以可视化的图解。再多的变量就无法用可视化方式来解释了，所以我们力求用简单的方式理解复杂的事物。

本部分最后是损失函数的讲解，着重说明了神经网络中目前最常用的均方差损失函数（用于回归）和交叉熵损失函数（用于分类）。
