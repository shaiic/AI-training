Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# 第9章 单入单出的双层神经网络

## 9.0 非线性回归

### 9.0.1 提出问题一

我们在第5章学习了线性回归的解决方案，但是在工程实践中，我们最常遇到不是线性问题，而是非线性问题。例如下面这条正弦曲线：

<img src="../Images/9/sin_data.png">

|样本|x|y|
|---|---|---|
|1|0.1199|0.6108|
|2|0.0535|0.3832|
|3|0.6978|0.9496|
|...|...|...|

问题：使用神经网络如何拟合一条有很强规律的曲线，比如正弦曲线？

### 9.0.2 提出问题二

前面的正弦函数，看上去是非常有规律的，也许单层神经网络很容易就做到了。如果是更复杂的曲线，单层神经网络还能轻易做到吗？比如下面这张图，给出如下一批训练数据，如何使用神经网络方法来拟合这条曲线？

<img src="..\Images\9\Sample.png">

|样本|x|y|
|---|---|---|
|1|0.606|-0.113|
|2|0.129|-0.269|
|3|0.582|0.027|
|...|...|...|
|1000|0.199|-0.281|

原则上说，如果你有足够的耐心，愿意花很高的时间成本和计算资源，总可以用多项式回归的方式来解决这个问题，但是，在本章，我们将会学习另外一个定理：前馈神经网络的通用近似定理。

上面这条“蛇形”曲线，实际上是由下面这个公式添加噪音后生成的：

$$y=0.4x^2 + 0.3xsin(15x) + 0.01cos(50x)-0.3$$

我们特意把数据限制在[0,1]之间，避免做归一化的麻烦。要是觉得这个公式还不够复杂，大家可以用更复杂的公式去自己做试验。

以上问题可以叫做非线性回归，即自变量X和因变量Y之间不是线性关系。常用的传统的处理方法有线性迭代法、分段回归法、迭代最小二乘法等。在神经网络中，解决这类问题的思路非常简单，就是使用带有一个隐层的两层神经网络。

### 9.0.3 回归模型的评估标准

#### 基本数学概念

- 均值 mean

$$\bar{x}=\frac{1}{m}\sum_i^mx_i \tag{1}$$

- 标准差 stdandard deviation

$$
std=\sqrt{\frac{1}{m} \sum_i^m{(x_i-\bar{x})^2}} \tag{2}
$$

- 方差 variance

$$
var=\frac{1}{m} \sum_i^m{(x_i-\bar{x})^2}=std^2 \tag{3}
$$

- 协方差 covariance

$$
cov(X,Y)=\frac{1}{m} \sum_i^m{[(x_i-\bar{x})(y_i-\bar{y})]} \tag{4}
$$

- 样本方差

$$
var=\frac{1}{m-1} \sum_i^m{(x_i-\bar{x})^2}=std^2 \tag{5}
$$

- 样本协方差

$$
cov(X,Y)=\frac{1}{m-1} \sum_i^m{[(x_i-\bar{x})(y_i-\bar{y})]} \tag{6}
$$

如果结果为正，表示X,Y是正相关。

#### 回归模型评估标准

回归问题主要是求值，评价标准主要是看求得值与实际结果的偏差有多大，所以，回归问题主要以下方法来评价模型。

- 平均绝对误差 MAE

$$MAE={1 \over m} \sum_{i=1}^m \lvert a_i-y_i \rvert \tag{7}$$

MAE对异常值不如MSE敏感，类似中位数。

- MAPE

Mean Absolute Percentage Error，绝对平均值率误差。

$$MAPE={100 \over m} \sum^m_{i=1} \lvert {a_i - y_i \over y_i} \rvert \tag{8}$$

- 和方差 SSE

$$SSE=\sum_{i=1}^m (a_i-y_i)^2 \tag{9}$$

得出的值与样本数量有关系，假设有1000个测试样本，得到的值是120；如果只有100个测试样本，得到的值可能是11，我们不能说11就比120要好。

- 均方差 MSE

MSE （Mean Squared Error）叫做均方误差，公式如下：

$$MSE = \frac{1}{m} \sum_{i=1}^m (a_i-y_i)^2 \tag{10}$$

就是实际值减去预测值的平方再求期望，没错，就是线性回归的代价函数。由于MSE计算的是误差的平方，所以它对异常值是非常敏感的，因为一旦出现异常值，MSE指标会变得非常大。MSE越小，证明误差越小。

- 均方根误差 RMSE

RMSE（Root Mean Squard Error）均方根误差。

$$RMSE = \sqrt{\frac{1}{m} \sum_{i=1}^m (a_i-y_i)^2} \tag{11}$$

是MSE开根号的结果，其实实质和MSE是一样的。只不过用于数据更好的描述。

例如：要做房价预测，每平方是万元，我们预测结果也是万元，那么MSE差值的平方单位应该是千万级别的。假设我们的模型预测结果与真实值相差1000元，则用MSE的计算结果是1000,000，这个值没有单位，如何描述这个差距？于是就求个平方根就好了，这样误差可以是标签值是同一个数量级的，在描述模型的时候就说，我们模型的误差是多少元。

- R平方 R-Squared

上面的几种衡量标准针对不同的模型会有不同的值。比如说预测房价，那么误差单位就是元，比如3000元、11000元等。如果预测身高就可能是0.1、0.2米之类的。也就是说，对于不同的场景，会有不同量纲，因而也会有不同的数值，无法用一句话说得很清楚，必须啰啰嗦嗦带一大堆条件才能表达完整。

我们通常用概率来表达一个准确率，比如89%的准确率。那么线性回归有没有这样的衡量标准呢？答案就是R-Squared。

$$R^2=1-\frac{\sum (a_i - y_i)^2}{\sum(\bar y_i-y_i)^2}=1-\frac{MSE(a,y)}{Var(y)} \tag{12}$$

R平方是多元回归中的回归平方和（分子）占总平方和（分母）的比例，它是度量多元回归方程中拟合程度的一个统计量。R平方值越接近1，表明回归平方和占总平方和的比例越大，回归线与各观测点越接近，回归的拟合程度就越好。

- 如果结果是0，说明我们的模型跟瞎猜差不多；
- 如果结果是1，说明我们模型无错误；
- 如果结果是0-1之间的数，就是我们模型的好坏程度；
- 如果结果是负数，说明我们的模型还不如瞎猜。

代码实现：

```Python
def R2(a, y):
    assert (a.shape == y.shape)
    m = a.shape[0]
    var = np.var(y)
    mse = np.sum((a-y)**2)/m
    r2 = 1 - mse / var
    return r2
```