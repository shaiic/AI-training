Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可
  
## 7.4 多分类结果可视化

### 7.4.1 显示原始数据图

与二分类时同样的问题，如何直观地理解多分类的结果？三分类要复杂一些，我们先把原始数据显示出来。

```Python
def ShowData(X,Y):
    for i in range(X.shape[0]):
        if Y[i,0] == 1:
            plt.plot(X[i,0], X[i,1], '.', c='r')
        elif Y[i,0] == 2:
            plt.plot(X[i,0], X[i,1], 'x', c='g')
        elif Y[i,0] == 3:
            plt.plot(X[i,0], X[i,1], '^', c='b')
        # end if
    # end for
    plt.show()
```

会画出下面这张图：

<img src="..\Images\7\source_data.png">

### 7.4.2 显示分类结果分割线图

下面的数据是神经网络训练出的结果：

```
epoch=98
98 1385 0.25640040547970516
epoch=99
99 1399 0.2549651316913006
W= [[-1.43299777 -3.57488388  5.00788165]
 [ 4.47527075 -2.88799216 -1.58727859]]
B= [[-1.821679    3.66752583 -1.84584683]]
[[0.01792798 0.73424896 0.24782305]
 [0.24569101 0.15450755 0.59980144]
 [0.38143011 0.37433317 0.24423672]
 [0.51185774 0.46432625 0.02381601]]
```

其实在7.2节中讲解多分类原理的时候，我们已经解释了其几何理解，那些公式的推导就可以用于指导我们画出多分类的分割线来。先把几个有用的结论拿过来。

从7.2节中的公式16，把不等号变成等号，即$z1=z2$，则代表了那条蓝色的分割线，用于分割第一类和第二类的：

$$x_2 = {w_{12} - w_{11} \over w_{21} - w_{22}}x_1 + {b_2 - b_1 \over w_{21} - w_{22}} \tag{1}$$

$$即：y = W12 \cdot x + B12$$

由于Python数组是从0开始的，所以公式1中的所有下标都减去1，写成代码：

```Python
b12 = (net.B[0,1] - net.B[0,0])/(net.W[1,0] - net.W[1,1])
w12 = (net.W[0,1] - net.W[0,0])/(net.W[1,0] - net.W[1,1])
```

从7.2节中的公式17，把不等号变成等号，即$z1=z3$，则代表了那条绿色的分割线，用于分割第一类和第三类的：

$$x_2 = {w_{13} - w_{11} \over w_{21} - w_{23}} x_1 + {b_3 - b_1 \over w_{21} - w_{23}} \tag{2}$$
$$即：y = W13 \cdot x + B13$$

写成代码：

```Python
b13 = (net.B[0,0] - net.B[0,2])/(net.W[1,2] - net.W[1,0])
w13 = (net.W[0,0] - net.W[0,2])/(net.W[1,2] - net.W[1,0])
```

从7.2节中的公式24，把不等号变成等号，即$z2=z3$，则代表了那条红色的分割线，用于分割第二类和第三类的：

$$x_2 = {w_{13} - w_{12} \over w_{22} - w_{23}} x_1 + {b_3 - b_2 \over w_{22} - w_{23}} \tag{3}$$
$$即：y = W23 \cdot x + B23$$

写成代码：

```Python
b23 = (net.B[0,2] - net.B[0,1])/(net.W[1,1] - net.W[1,2])
w23 = (net.W[0,2] - net.W[0,1])/(net.W[1,1] - net.W[1,2])
```

完整代码如下：

```Python
def ShowResult(net,X,Y,xt):
    for i in range(X.shape[0]):
        category = np.argmax(Y[i])
        if category == 0:
            plt.plot(X[i,0], X[i,1], '.', c='r')
        elif category == 1:
            plt.plot(X[i,0], X[i,1], 'x', c='g')
        elif category == 2:
            plt.plot(X[i,0], X[i,1], '^', c='b')
        # end if
    # end for

    b13 = (net.B[0,0] - net.B[0,2])/(net.W[1,2] - net.W[1,0])
    w13 = (net.W[0,0] - net.W[0,2])/(net.W[1,2] - net.W[1,0])

    b23 = (net.B[0,2] - net.B[0,1])/(net.W[1,1] - net.W[1,2])
    w23 = (net.W[0,2] - net.W[0,1])/(net.W[1,1] - net.W[1,2])

    b12 = (net.B[0,1] - net.B[0,0])/(net.W[1,0] - net.W[1,1])
    w12 = (net.W[0,1] - net.W[0,0])/(net.W[1,0] - net.W[1,1])

    x = np.linspace(0,1,2)
    y = w13 * x + b13
    p13, = plt.plot(x,y,c='g')

    x = np.linspace(0,1,2)
    y = w23 * x + b23
    p23, = plt.plot(x,y,c='r')

    x = np.linspace(0,1,2)
    y = w12 * x + b12
    p12, = plt.plot(x,y,c='b')

    plt.legend([p13,p23,p12], ["13","23","12"])

    for i in range(xt.shape[0]):
        plt.plot(xt[i,0], xt[i,1], 'o')

    plt.axis([-0.1,1.1,-0.1,1.1])
    plt.show()
```

改一下主函数，增加对以上两个函数ShowData()和ShowResult()的调用：

```Python
if __name__ == '__main__':
    num_category = 3
    reader = SimpleDataReader()
    reader.ReadData()

    ShowData(reader.XRaw, reader.YRaw)

    reader.NormalizeX()
    reader.ToOneHot(num_category, base=1)

    num_input = 2
    params = HyperParameters(num_input, num_category, eta=0.1, max_epoch=100, batch_size=10, eps=1e-3, net_type=NetType.MultipleClassifier)
    net = NeuralNet(params)
    net.train(reader, checkpoint=1)

    xt_raw = np.array([5,1,7,6,5,6,2,7]).reshape(4,2)
    xt = reader.NormalizePredicateData(xt_raw)
    output = net.inference(xt)
    print(output)

    ShowResult(net, reader.XTrain, reader.YTrain, xt)
```

最后可以看到这样的分类结果图，注意，这个结果图和我们在7.2中分析的一样，只是红线斜率不同：

<img src="..\Images\7\result.png">

上图中的四个圆形的点是需要我们预测的四个坐标值，其中三个点的分类都比较明确，只有那个绿色的点看不清楚在边界那一侧，可以通过在实际的运行结果图上放大局部来观察。

### 7.4.3 理解神经网络的分类方式

上图中：
- 蓝色线是1|2的边界，不考虑第3类
- 绿色线是1|3的边界，不考虑第2类
- 红色线是2|3的边界，不考虑第1类

我们只看红色的第1类，当要区分1|2和1|3时，神经网络实际是用了两条直线（绿色和蓝色）同时作为边界。那么它是一对一方式还是一对多方式呢？

理想中的一对多方式：

<img src="..\Images\7\OneVsOthers.png">

我们想象中它应该但是并没有画出上面这样的分割线来：只看红线，它把红点和其它点一次分割成型。而神经网络没有画出这样的线来，这意味着神经网络不是一对多方式吗？

程序的输出图上的分割线是我们令$Z1=Z2, Z2=Z3, Z3=Z1$三个等式得到的，但实际上神经网络的工作方式不是这样的，它不会单独比较两类，而是会同时比较三类，这个从Softmax会同时输出三个概率值就可以理解。所以，当我们想得到第一类的分割线时，需要同时满足两个条件：

$$Z1=Z2，且：Z1=Z3 \tag{4}$$

这就意味着公式4其实是一个线性分段函数，而不是两条直线，即下图中红色射线和绿色射线所组成的函数。

<img src="..\Images\7\multiple_result_true.png">

同理，用于分开红色点和其它两类的分割线是蓝色射线和绿色射线；用于分开绿色点和其它两类的分割线是红色射线和蓝色射线。这样就可以解释神经网络确实是一种一对多的分类方式了。

这个结论正确吗？前面我们提到过，训练一对多分类器时，是把红色样本当作一类，把蓝色和绿色样本混在一起当作另外一类。而我们在此并没有那样做，三类样本在训练时是完全分开的。所以我们只能说神经网络从结果上看，是一种一对多的方式，至于它的实质，我们在后面的非线性分类时再进一步探讨。

### 代码位置

ch07, Level2


### 思考与练习

1. 使用一对一的方法训练三个二分类器，来解决此问题。
