 昨天我们在涉及到真正真的线性回归之前,我先讲了一些记不得概念.

主要三个概念,1反向传播，2梯度下降，3损失函数。

模型的过程中主要做几件事，第一件事我们有一个输入输出，我们都会把它预处理一下，之后归到模型里面，然后把模型进行训练。

训练后就会得到一个模型文件，模型文件里面都是我们训练好的W、B信息，有了这个模型文件，我们就可以处理实际的问题，进行新的预测，我们叫他模型的推理。

昨天我们在讲模型训练，前向计算，怎么就算这算这一关误差或者损失呢。

我们要找到这之间的一一个区别或者差距，cost/loss function 有了这个损失函数，我们就知道我们算出的结果跟真实值之间的差距，找到差距就要把他传回去，传回去的过程，非常重要的一个概念就是反向传播，其实就是利用了梯度下降的一个功能，不断的降低梯度，不断反向回去。求导，计算偏差，转到前向计算。损失函数达到一个确定的值，把他结束，否则再次循环。

梯度这么算的呢
$$
\theta_{n+1}=\theta_{n}-\eta \cdot \nabla J(\theta)z
$$
真正我们求方向传播时就是用的这个公式。

反向传播四大公式，一般不需要你来推，当是我们时抱着一个学习的态度来了解。

大家打开1.2四大基本公式，我们来推一下。
$$
\begin{array}{c}{\delta^{L}=\nabla_{a} C \odot \sigma_{\prime}\left(Z^{L}\right)} \\ {\delta^{l}=\left(\left(W^{l+1}\right)^{T} \delta^{l+1}\right) \odot \sigma_{\prime}\left(Z^{l}\right)} \\ {\frac{\partial C}{\partial b_{j}^{l}}=\delta_{j}^{l}} \\ {\frac{\partial C}{\partial w_{j k}^{l}}=a_{k}^{l-1} \delta_{j}^{l}}\end{array}
$$
C=cost function=损失函数跟你计算值和真实值之间的差距。A非线性函数，Z线性函数。



昨天那个ch4d的路径问题，file_name = "../../data/ch04.npz"，然后我们发现上面不是有个pythpn debug console，如果这个不是cmd的你是powershell的改一下。改成cmd把poweshell删掉。

然后这个真实的问题的出在哪，中文字符解析会出问题，然后就给了一个相对路径出来，但是这是相对路径又有一个问题，到底对谁的路径。

我在这打印一个信息，我在这加一下东西看起来方便，然后我再打一个return。然后我们打印出这个信息，仔打印一个东西，我们打出详细信息。windows反斜杠就是有一个问题，就是没办法转成绝对路径。

进不去，对，我们看他少了一层，所以就算用绝对路径也少了一层，cwd当前工作目录，你给相对路径其实不是当前路径，sourcecode上传也有一个路径。所以一种方式是你把他减一个点，但是这样来说，在这个code里面能用，在其他code里面就用不了了。因为你对这个来说是相对的在其他路径就不行，在进入04这个目录下的sourcecode运行就可以。所以每次进入当前目录下运行。还有变成一个觉得路径就可以。大家跑的时候进入ch04目录下。在我们做模型的时候就要协调好，用英文的话就可以直接写绝对路径了，可以不解析了，中文总识别不了。



然后继续我们刚才讲的内容。先休息一会。

只有真正敲代码，你才能够了解他的原理。我们开始讲第四部分了。

第一部分，基础知识我们过去了，请大家反复读一读。然后第二部分线性回归，他其实分了两个大块，最简单的就是有一个神经元。 hyphais假设函数，线性函数，然后我加了一个非线性函数。非线性的每一个可以带激活函数也可以不带。我们说最简单的神经元，就是单入单出。你给他一个x输出A或者C。第四章我们要讲两种，一种单入单出，一种多入单出。昨天我们讲了最小二乘法，最小二乘法它通过最小化误差的平方和寻找数据的最佳函数匹。

通过最小二乘法，通过对w和b求偏导，再令偏导数为0，昨天我求值的时候比较复杂，但是计算不会那么复杂。所有的公式，你把值输进去自动求值，然后呢，这个矩阵跟标量求值也是很简单的。

我们get到了这个值后，我就在神经网络值去做比较得到一个差。

我们来讲梯度下降的核心就是损失函数对吧，不断的让损失函数越来越小，梯度下降的原理，预设函数为一个线性函数。
$$
\operatorname{loss}(w, b)=\frac{1}{2}\left(z_{i}-y_{i}\right)^{2}
$$


这个理解清楚了后面的也就都清楚了，这个能明白吗？因为这个事单个样本，所以这里是二分之一，如果是多个样本，2m分之一，求偏导
$$
\begin{array}{c}{\frac{\partial \operatorname{los} s}{\partial w}=\frac{\partial \operatorname{loss}}{\partial z_{i}} \frac{\partial z_{i}}{\partial w}=\left(z_{i}-y_{i}\right) x_{i}} \\ {\frac{\partial l o s s}{\partial b}=\frac{\partial \operatorname{loss}}{\partial z_{i}} \frac{\partial z_{i}}{\partial b}=z_{i}-y_{i}}\end{array}
$$


一个神经元是超级简单的，我们来看看代码，这个代码做了什么。首先呢，第一步就是reader.ReadData，先初始化一个SimpleDataReader类，经常使用。然后计算，然后这后面是什么？反向传播，然后求梯度下降，损失函数没有列出了。是不是不是很简单，然后X，Y都有了，B也求出来了，这个结果也就有了。整个样本都遍历了一遍，得到一个结果。还记得上次得到的是多少？第一次得到的值W=2056827，b2.965434，为什么差距会这么大呢，一会我们来讲为什么会差那么多。有很多很多原因，我们想想有哪些地方值得改进。我们看了梯度下降，然后我们看神经网络，我们把例子摆在这。初始化权重，释放一个解，然后求误差，然后调整权重。首先呢定义一个社交网络结果，一个输入一个B输出Z也没有激活函数，然后就搞定了。有一个X，有WB作为参数，然后他的输出层就是我们要预测的那一个。然后我们反向传播，过程就是跟上一次也是一样，所以整个结构也是一样的，结果也是差不多。神经网络写起来很复杂，我先给大家一些时间看一下。

其实梯度下降就是神经网络的一部分，我来看这个代码的优点在哪里，这是一个简单的实现，把他们融合在了一起。首先我们要初始化，在这里权重为0，后面我们会看到权重初始化的操作，然后是前向计算，然后是返回反向传播梯度下降的结果。然后去更新权重，然后是训练模型。训练1过程就是我们把样本都喂给他，先get到数据，然后做前向运算，直到做一个限制结束。接下来是模型推理，推理的过程什么，就是你有一个新的预测值，前向计算将我们训练好的模型权重数据和我要预测的特征值放进去，然后出一个结果。但是为什么我们的神经网络跟这个不一样，是因为我们的发布数据比较多。用蓝色的点表示XY用红色的线表示train值。

然后我们要解决我们的历史遗留问题。在单层的代码中我们使用的一个样本，每次都算一次，相邻的样本相互抵消会出现一些问题，使用在我们实际使用中，第一个改进就是我们要使用多个样本计算，不再是一个一个样本了。

那么我们来看看，如果他是一个矩阵，向量的模式来怎么算呢，前向计算就成了一个矩阵的计算，w乘以b得到一个输出。那我的forward就是三个样本，这个z其实就是一个三行的数组，损失函数多个的时候就是
$$
J(w, b)=\frac{1}{2 m} \sum_{i=1}^{m}\left(z_{i}-y_{i}\right)^{2}
$$
当他转换成矩阵是怎么算的呢*s**u**m*(*Z*−*Y*)^2，这个公式在python里面怎么算的呢，按元素做减法，做完减法之后，做完减法之后就是按元素求和。所以当我们做loss的时候就是这个样子，然后我们在求梯度的时候也是一样J对w的偏导
$$
\begin{aligned} &=\frac{1}{m} \sum_{i=1}^{m}\left(z_{i}-y_{i}\right) x_{i} \\ &=\frac{1}{m} X^{T} \cdot(Z-Y) \end{aligned}
$$
然后就得出这么一个结果。
$$
\left(\begin{array}{lll}{x_{1}} & {x_{2}} & {x_{3}}\end{array}\right)\left(\begin{array}{l}{z_{1}-y_{1}} \\ {z_{2}-y_{2}} \\ {z_{3}-y_{3}}\end{array}\right)
$$
一行乘三列最后变成一个向量。

X样本，之前我们是怎么说的，我们是把行作为特征值的个数，列作为样本个数，所以三个样本应该是一个列。所以变成横才能计算出结果。求b也是这样。我们一起来看看这个代码

```
   def __backwardBatch(self, batch_x, batch_y, batch_z):

       m = batch_x.shape[0]

       dZ = batch_z - batch_y

       dW = np.dot(batch_x.T, dZ)/m

       dB = dZ.sum(axis=0, keepdims=True)/m

       return dW, dB
```

那我们这个多样本的计算就说完了。

最后一个就是比较罪行二乘法，梯度下降法，神经网络，那么这个神经网络哪里出错了呢。

我得从始终梯度下降的三种形式说起，首先是单样本随机梯度下降。





然后他有什么特点呢，就是他的坡度非常的大，损失函数值波动大。然后呢，刚才我们训练的那个代码，他没有训练到最低点，他在中间就停了。为什么你，因为我们就100个样本，真正在我们在做的时候肯定是要loss小于某个值的时候才能结束，样本方式迭代了300次，一次样本100个，用了三回后达到了精度要求。所以第一个原因就是训练的时间太短次数不够，第二个是什么呢，单样本波动很大，左右晃动。

我经常使用的小批量样本梯度下降，每次取一个批量的样本，然后训练一个批次，这个彼此好处在于受单样本噪声影响，平滑的下降，训练速度较快。不好的在于使用310次的迭代，一次训练10个样本。其实他一共走了三千多步，相当于训练了31遍，那么整个数据量偏大了，

第三个呢，叫做全批量样本梯度下降。一次把所有样本都操作一遍，但是他一个大问题是，一次取100个，迭代了308次，整个样本计算量比较大的，不适合大样本的训练，数据量较大时受内存限制，训练过程慢。所以一遍情况下我们都会选择Mini-Batch。

一般大家做的时候，都会把样本打乱顺序，因为你每次训练，其实每次相邻的偏差都差不多，所以每次都是随机选取的，这样训练的才更好，我们看这里有没有对比。那我们看下相关的概念，Iteration：迭代，一次正向+一次反向。十个样本一次进去出来就是一个迭代，所以呢你迭代多少次就说明样本使用了多少次。Epoch呢就是所有样本被使用了一次，叫做一个Epoch。然后呢我们要理解这个概念，以后在代码里重复出现，这是一个非常非常重要的概念。

然后我们来看看代码。

做了一个整个搭神经网络步骤的问题，然后是怎么算了的。然后我们给大家十分钟的时间看一下。然后一会我们来讲。大家可以看一下。

最重要的一件事就是初始化W跟B，请问这里的W跟B是一个几乘几的矩阵。如果wb错了，那么训练的就是错的。最简单的方法在这，直接打印出来不就好了，可以拿这个minibatch做例子。是不是特别蒙，我们看这个怎么做的，WB其实只有一个，多样本是他多了很多X跟z所以wb是一个的，值单入单出然后第二个就forward的过程。矩阵的乘法，反向传播X一定要求转置。所以要loss的保存中间值。



Batch Size如果是-1的时候，他是全批量的训练，否则的话，是你输入的这个值对吧，然后我们就看到了这个迭代，然后我们看到的是迭代，迭代是走完一遍样本要用多少次是吧。这个次数是总次数除以minibatch的次数。

一般我们的 batch都是怎么设置打乱顺序的，一般有两种实现方式，一开始你先取一个数组，然后把编号打乱，这个顺序打乱之后呢，不会有任何重复的，漏去取的。到处随机取肯定是不行的。

而且每次样本都被打乱了，然后其实还有另一种实现方式，他全部给你打乱，然后你要几个就给你返回几个值，差不多，只不过实现的方式不一样，把0到100个样本随机取值。

然后每次迭代的时候看看这个loss符合不符合这个范围，打印出来。这样打印出来的结果跟我们的结果相差不了多少。

休息在继续。

跟大家商量个事，我们先将课件知识点，然后再减代码。好，我们快速进入正题。

上午我们讲了单入单出，单入单出的特点是什么呢，一个神经元，inputsize是1，outputsize是1。

那我们再稍微难一点讲多入单出的单层神经网络，input是3次，output依然是1次，那么他仍然是一个线性的网络，所以我们不需要考虑激活函数的问题。下一张，讲到分类就需要分类函数就需要用到激活函数，

我们讲的单入单出机房空调功率，我们只设置了一个因素，就是空调台数，台数越多功率就越大。

预测也是服务器有多少台，需要多大的功率。

这一次呢，我们提出一个问题，就是需要多个参数来一起考虑的，就是比如说距离市中心十五公里，九十平米的房子有多少钱呢。这么通过神经网络来实现呢？

我来算一下预测房价问题，这是一个入门问题。

假如我们这里有一千个样本，然后我们取两个特征值，居住面积、地理位置这两个特征，地理位置这个信息呢是距离市中心的距离。居住面积就是大小，那么价格呢就是在最后，这个价格有点偏低了。

我们来看一下特征值，在我们的练习里可以，然后看最大值最小值，以及平均值。样本为什么要统计最大值最小值，以及平均值呢？在后续的过程中我们发现他的用途。

这个数据是三维的，我们有居住面积、地理位置以及房价。这个方向是地理方位，那个方向是居住面积，画成了一个三维图，你可以把它想象成画了一块平面。把草坪分成了两块，就需要两个权重一个w1一个w2，那么这样就需要一个多维的模型，我们把它变成一个通用的一个方式就是这样的$$y=a_0+a_1x_1+a_2x_2+\dots+a_kx_k$$

这里为什么是a0呢，我们把x取值为1。我们刚刚说了多元线性回归是多个输入，多重线性回归是指有很多个输出。这样我们就可以简化公式成为wb的形式，
$$
z = x_1 \cdot w_1 + x_2 \cdot w_2 + b
$$
把x放入w前，然后呢理解下这个多元，就是有多个样本，那么这个怎么设计呢，影响房价的因素有很多，比如地理位置等等，那么怎么挑选呢，自变量对因变量必须有的影响，并呈密切的线性相关，第二个是必须要是真实的，自变量之间一定要有一个互斥性，比如你把房屋的面积作为一个参数，你就不能房屋的边长作为一个参数，这两个关系其实一致的。

然后第四个自变量应具有完整的统计数据，其预测值容易确定。那么现在对于这个问题，按我们以往的思路，肯定是先求一个数学题，然后是做解，两个做一个对比，现在呢我们就用正规方程来解决，一会我们再来看这张表，

一会我们再来对比梯度下降跟正规方程的要求。正规方程法跟最小二乘法其实类似。那简单的我们做一下推导，是什么wb有关系的一个函数，然后就这样一个函数$$y=a_0+a_1x_1+a_2x_2+\dots+a_kx_k $$然后命令b=w_0，就得到这样一个函数。然后还可以吧x0设置为1，这样的话就是m个样本，n个特征值，就是这样一个矩阵，每一行是一个矩阵，如果我们把m个样本一起计算，将会得到下面这个矩阵，有n个，n是特征值，w永远跟特征值有关系，m跟样本个数有关的。

然后预测的真实的就是y是一样的，请问y是多少呢，是m个样本的，所以是一个1乘以m的矩阵。所以呢是x乘以w，所以最后两个一除，这样预设函数的输出与标签值就一致了，在矩阵中求得话首先要求一个逆矩阵，得是一个方阵才能求逆矩阵，在等式两边同时乘以X的转置矩阵，得到X的方阵，所以如果这个方阵有逆矩阵一定可以求出来。所以w可以求出来了。



然后可以求出W的正规方程的解。

然后呢，更复杂的推导方法，这个在后面我要经常用到的两种方式，这个是用损失函数来推，把z=XW计算公式带入，并变成矩阵形式$$J(w) = \sum (x_i w_i -y_i)^2=(XW - Y)^T \cdot (XW - Y) $$

这个怎么得到呢，大家能推导出来吗，有谁能明白的上来推一下。其实这个方法很简单，我们举一个例子。

然后呢对w求导，再对b求导。



最后给大家看一看，最后结果很简单$$W = (X^T X)^{-1}{X^T Y} $$，然后呢这样的话对他的要求就很满了，这个逆矩阵如果不存在，这样的话就会被消掉，没办法求到一个矩阵的逆了。对就是不是满秩矩阵。

李牧的课深度学习，他讲的特别有意思。

然后我们看这个代码的实现，两个特征值，然后呢代码大家回去看一下，课上就不给大家看了。

然后呢就get到了整个数据， 取得num_example = X.shape[0]是行数对不对。行数就是样本数。

然后我们看这一行代码one = np.ones((num_example,1))，那个one大家知道什么意思吗，对那么有一千行一列的向量全部是1，要插入到x中去，column_stack就是按列去插，X[0:num_example,:]什么意思。讲的是两维，第一个是行0到1000，列是所有的就是两列。就是0到2。然后底下就开始求了。c = np.linalg.inv(b)就是求他的逆，然后e = np.dot(d, Y)就是点乘0到n的过程，然后就把这个结果打印出来。z = w1 * 15 + w2 * 93 + b预测事多少了。这一章是解决怎么把问题搞定。

那我们用神经网络怎么求？

一个最简单的单层单点神经元，第一个样本的第一号第一个样本的第二个特征值，y就是一个真实标签值。所以一共有1000个样本，每个样本2个特征值，X就是一个1000 ×2的矩阵。

那么w跟b，w一定跟特征有关，所以有两个w。然后呢一层只能有一个b。

所以呢，最后Z就是这种形式的Z=XW+B的形式，

这就是一个二行一列的矩阵，损失函数使用均方差函数。

如果是单样本的话$$
z_{i}=x_{i} \cdot w+b
$$，多个特征值就是分别求导w1w2，然后就是这么一个公式。
$$
\begin{array}{l}{z_{i}=x_{i 1} \cdot w_{1}+x_{i 2} \cdot w_{2}+b} \\ {=\left(\begin{array}{cc}{x_{i 1}} & {x_{i 2}}\end{array}\right)\left(\begin{array}{c}{w_{1}} \\ {w_{2}}\end{array}\right)+b}\end{array}
$$
然后对于b的话就不用看了。w值把他变成一个矩阵形式。$$
W=\left(\begin{array}{l}{w_{1}} \\ {w_{2}}\end{array}\right)
$$
然后多样本多特征值的计算，

就是要我们多个样本一起算。一次多几个样本就是z1z2z3，还是一个输出至少多了好几个样本。所以他仍然是多个输入一个输出这样一种情况。

然后假如我们是这个样本，然后看这个公式求导
$$
{J(w, b)=\frac{1}{2 \times 3}\left[\left(z_{1}-y_{1}\right)^{2}+\left(z_{2}-y_{2}\right)^{2}+\left(z_{3}-y_{3}\right)^{2}\right]}
$$
然后大家只需要知道这个结论就行了$$
\frac{\partial J}{\partial B}=\frac{1}{m}(Z-Y)
$$

单样本是一个标量放前放后都行。转换成矩阵的形式，转换成列向量就是一个T。多样本是一样的效果。

然后代码可以实现了，一会给大家看看这个代码。

这个什么意思？nan的意思是数值异常，导致计算溢出了，没法出来值了。

我计算没有错，推导也是对的。为什么开始计算的时候出问题，然后怎么办，调小迭代一下看看什么原因。

方向第十个的时候值就超级大了，后面就爆表了，叫梯度爆炸这么一个问题。已经有成熟的方法来解决这个问题了。那我们一起来示范下这个原因。

我们看这个debug问题，第一次运行前向计算，由于W和B初始值都是0，所以z也是0，这是正常的。

然后求dW和dB的值都非常大。这是什么原因呢，因为batch_z是0，batch_y是244.078，二者相减是-244.078，因此dB就是-244.078，dW因为矩阵乘了batch_x，值就更大了。那为什么会出现这个问题呢，所以这个值就飙升了。

其实有一个方法就是用来防止这个问题，叫做归一化。所有的X值都是在[0,1]之间的，

基本上所有数据拿过来都要做归一化的，我把所有数据都要放到01之间。



神经网络是以样本在事件中的统计分布概率为基础进行训练和预测的，所以它对样本数据的要求比较苛刻。

第一个就是要各个特征的取值要符合概率分布，就是不能超过1。

第二个呢，并没有办法去比较1米和1公斤的区别，但是我们知道了1米在整个样本中的大小比例，以及1公斤在整个样本中的大小比例，比如一个处于0.2的比例位置，另一个处于0.3的比例位置，就可以说这个样本的1米比1公斤要小。

第三呢，就是神经网络假设所有的输入输出数据都是标准差为1，均值为0，包括权重值的初始化，激活函数的选择，怎么在激活函数范围呢。

综上所述，以及各种问题。

这样梯度下降就比较严格柔和

然后归一化的概念，分为几种归一化，归一化，标准化，中心化。

我们基本上用的是第一个，$$
x_{n e w}=\frac{x-x_{m i n}}{x_{\max }-x_{\min }}
$$
然后标准化$$
x_{n e w}=(x-\overline{x}) / \text { std }
$$

最后一个就是中心化，所有样本都减去一个平均值。

然后我们在看我们的样本数据，我们把它归一化成这个样子，然后我们再看这个代码实现。

```
 col_i = self.XRaw[:,i]
max_value = np.max(col_i)
min_value = np.min(col_i)
*# min value*
self.X_norm[0,i] = min_value 
*# range value*
self.X_norm[1,i] = max_value - min_value 
new_col = (col_i - self.X_norm[0,i])/(self.X_norm[1,i])
X_new[:,i] = new_col
```

然后我们发现求出来后还是有问题。损失函数特别大。

所以为什么呢，最后求出来的解并不是我们要求的解。

可以看到loss值、w1、w2、b的值，每次跳跃都很大，怎么降低呢。

第一个学习率缩小10倍，变成0.01，第二个max_epoch扩大50倍，还有一个batch_size=10，使用mini-batch批量样本训练。

发现解决了他浮动的问题，没有解决他下降的问题。

归一化的数据对比一下，比值的变化有规律。还原真实的W,B值，真实的样本值是X*X*，真实的权重值是W*W*；在归一化之后，样本值变成了X'*X*′，训练出来的权重值是W'*W*′
$$
\begin{aligned} y &=x_{1} w_{1}+x_{2} w_{2}+b \\ z &=x_{1}^{\prime} w_{1}^{\prime}+x_{2}^{\prime} w_{2}^{\prime}+b^{\prime} \end{aligned}
$$
通过这样一个计算出来的结果就差不多了

但是做这么一个操作有点麻烦，还有一种方法就是我把预测数据也归一化。

所以预测归一化，我把训练得到的数据记录下来得到最大值最小值。相当于我们把预测数据混合到训练数据里面了。然后求出这样一个值。记录了之前训练数据的最大最小值。

我们是看到问题然后去解决问题，然后大家已经有一套解决的方法。

试一试看看哪个方法得出来的值比较好。

有很多现成的归一化方法，直接copy下来就好了。

那么最后一个，就是标签值归一化，最后还是不太对，因为是0到1，需要在倒腾回去。基本上就是这三种方法。

第一个X值做归一化，否则训练都训练不了，直接溢出

第二个Y值不在01之间，归一化好了，迭代次数就少了，y做了归一化，还有返回得到一个真实值。

那么我们就来看代码吧。

多样本主要处理的问题是什么呢，数据不去处理的偏差。

我们来看一下，05的 level5_NormalizePredicateData，ch05 。

留两个作业，一个作业是请把ch05code，level5所有要用到的函数重新写一遍，写在一个文件里。

level4自己写一个非门逻辑。作业05的5和04的6，一个归一化，一个网络。

