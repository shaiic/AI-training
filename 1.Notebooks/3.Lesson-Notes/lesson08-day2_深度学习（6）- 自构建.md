# lesson08-day2_深度学习（6）- 自构建

## 13

大佬讲的都是前沿科技，然后这次我们又回到基础来了，可能这回大家在听基础的时候就会觉得，哎哟，天那么简单的，大家也包容包容，还要继续听一下的。那今天，主要是讲两个内容，一个是我们的，我们可以看我们的这个报道。在我们的这个AI社区里面，这个网有点慢，好吧，那我就这样吧，其实在我们的这个ACTION的这个社区里面，大家可以看到其实B并不是教学案例嘛，那咱们之前讲了一直都是B6，这个其实网络的基本原理，但其实我们除了BTwo外，还有很多其他的东西。

 上次讲过一个看图识熊，然后，讲过一个对那个智能家居。然后其实我们还有比这个看图、智能家居更简单的例子，就是图像识别理最简单的手写数字识别。然后，它的扩展版的手写算式计算器，一个是B七，一个是B九，今天我们就来讲B7和B9，然后还有一个叫B13是我们的实习生做的一个案例，然后叫AI这边生产，然后我们也进行了一些改进，不过那个改进版本还没有放上来，有一些LICENSE的问题，还有一些data的问题，所以我们这个BETAS，我们弄差不多了，然后code都整理好了再放上去，这个案例，有这个整个的步骤，然后还有一些，这个部分我能放上来的扣子，我都放上来了。但看这个code估计也跑不通这个东西，所以今天就给大家来讲一讲这些东西怎么搞的，所以今天主要内容是，这里面自构建的B七B九还有B十三的内容。我的主要的那个侧重点在哪里，就是简单的内容，我们给大家多讲讲，复杂的内容，就给大家展示一下。然后，力争大家每个人都能听明白了，然后大家如果有不明白的，可以及时举手问，那个我前一阵听了一个讲座讲这些。然后那个讲课的人的是我们那个博士实习生，然后之前我主要没有接触这个，然后在那儿听的时候，然后他在前面讲的讲了讲的时候就说，大家这个故事，这个故事然后，这个都明白吧，然后一开始我们比还有人提问题，后来都不说话，然后，然后他这个明白吧，行过去，因为我们大家都不说话，然后终于明白了，这个听不懂，又不知道该如何问的心情是吧。

我就突然发现，哎呀原来就是讲的人自己为这个事明白的听的人可能觉得一头雾水，所以大家千万别不好意思，如果有不明白的赶紧问，但是我觉得应该没问题，因为这东西实在太简单了，对大家智商，如果我就是就是真的是不能够那个低估大家的。这东西就是就是就是其实很简单，而且我会按照最简单的方式给大家讲，所以，我们今天就开始讲了哈，这也没有网，所以他给大家展示一些网页展示不出来。就就先这样了，那我现在放一个SIZE，我们是结合这个来给大家讲，所以很简单。code我一会儿给大家展示，然后就大家就不用那个，对我突然对么，刚才进去了，就是慢，如果有人能帮忙解决一下网络问题，简直是太棒了。

那个今天我们就讲这个MNIST，知道是什么吧，有多少人知道，他其实是一个那个数据集这个数据集是做了什么，我们可以从MNIST有一个官网上来看到，大家在网上搜那个基本上都会。可以做到这个官网这个数据集，这是一个手写数字的一个数据集里面一共存了多少呢，他是把手写的数字零到九，这些数字存成了就是存成了那个四个文件，前两个文件，就是训练集及后两件测试集，然后其实都是图像图片文件，每一个文件其实是28乘28的一个，这个28乘28的一个图像，然后，给他转成了就是，此次节礼物，然后存进去的，然后就是它到底是零到九个哪一个数字标标签，那这个，是一个MNIST数据集，这个数字集是由两部分组成的一个最初的时候是NST，后来又增加了一些其它的，这个就增加了一些这个数据，增加了一些图片，然后就变成MNIST，这是一个手写字体。识别一个最经典的，一个数据集，而且是学深度学习的HELLOWORLD，所以，今天我们学习的都是最简单的东西，

所以大家如果想了解这个，这个东西，可以上这个网站上去看就是了，他们用的，然后这里面有好多办法，就是不同的算法的对比等等，然后还有对这个数据集到底是什么样的形式的一个介绍，然后这是一个自己识别的，给大家会展示一下，这个到底里面是什么样子的，我看看我能不能看到我要展示内容，我先把该展示的东西东西都打开，有没有把那个放哪去了。

给大家来简单介绍一下到底这个我们要做的是什么，我们就放到那个方块，然后MNIST这个东西，其实是一个AI实战的一个内容，也是我们就跟AI的COMMUNITY社区的一两个教学案例，然后这个案例，分为一个简单的一个，那个升级版，简单版的就是我乘坐MVC，然后，付升级版就成为MDC，然后简单保密大家详细介绍，升级版比较稍微难一些，然后就，大家可以自己感兴趣自己钻研。

然后那什么是MNIST的，刚才我们说了，那个是一个这个手写字体的一个数据集，这个数据集有多少，他一共收集了6万个训练，它是有分为训练集，结果说刚才看到我们的那个网站上他的训练集、测试集，他训练集是收集了6万个实例6万个例子，然后测试及收集了1万个例子，所以加是7万个，然后，这些例子他们，我们用这个就是不同的图片吗，他有6万个图片做训练集，1万个心图片作为测试集，然后这个图片的都是多大的，都是28乘28个像素的，然后也就是就是行驶28乘28的矩阵，就是28乘28的这个像素的这么一个矩阵，然后存存起来，形成了这个Byte字节。

这个官网的就是刚才我打的这个东西，大家可以看，然后在这里面，我统计了一下，这里分别有零到九，这十个数字。每个数字在这个train里面到底有多少个，每一个大概都是6000左右，然后可能少了5400之类的，然后，那个他就在大概都在1000左右，然后是这样的一个数据。然后那它有一个Dataformat的，那在这里面，这个数据到底什么样的形式来存着，我们说不管是train还是test我们肯定都分为两个部分，一个是什么，一个是他的这个真正的这个手写字体对吧，从零写到九。那还有就是什么，我们训练的时候，我们说我们现在学习的深度学习都要什么有监督训练，什么叫有监督训练，就是你每一个训练集的东西和测试集里面东西，所以要有监督，那我们再来看一下它的image和label都是什么样子的，其实是这种格式来存储的。他一共就是有这个16个字节，然后他image只发我们前面四个32字节的，为32字节的位置一共16个字节，他存的是什么，存了一些，就是头信息，第一个32字节存在就是魔术，然后就不用管了，反正就是记录这个文件到底是不是就正确，大家就是有没有被人篡改这样一个信息，随便弄了一个数，然后底下，那个第二个32字节存了一个什么，存了一个文件里面有多少个image，那就是训练集对吧，所以他有6万个，然后，那这里又下一个32字节的存了什么，到底有多少行吗，然后28列，所以他是一个28乘28的一个图片，然后在底下，就是哪一个图片底下这些这些东西，就是每一个图片，然后它每一个像素那也就是说，那都是都是一个什么，就是一个一个值对吧，我说28乘28的每一个像素点，他其实是一个零到二五五之间的一个值，在这里，所以他就用一个，一个字节来存的都是32，那个BT就是四字节的一个东西，然后这种就是一个字节的，然后八个byte的一个东西，28乘28那就是一张图片了。

对这个不是RGB的图片，一会儿我来看看他的形式，所以在我们训练的时候，我们要特别强调一下，因为它是单通道的，他不是三通道，而且它存在这个形式跟我们平时，RGB的那个表示方式还是不太一样的，所以，我们一会儿还想需要看一下，如果对他进行训练的话，其实我们需要对所我们的东西进行一些预先处理的，那这里他是零到九的Value就是十个Value，然后分别表示就是手写的这个字体的数字的零到九，然后第一个也是魔术，然后后面就是有6万个，训练集里面的这个标签，然后底下的所有的字简单一些，到底表示哪个这种形式，然后我们看看这里面在训练的，训练的这个在imagefile里面，他是这样子的，他底下有一个例子，这都是从官网上截的图片，但这些文件，是这些就这像素都是，按行来存的，也就是说在一行一行的单位存的，但是他零意思是什么，意思是什么，255的意思就是黑的，就是数字对吧，但其实在我们的APP里面，这里我们把零代表什么，零一般都是黑的吧，然后二五五一般都是白。他们是把二五五其实我们要显示出来的时候，你就会发现他其实背景是黑的，前面字四个白的那种项目图片，但是他这种表示方式，它不是按RGB表示的。所以我们知道他的表达方式是什么，他们把零表示成白，其实你黑白什么的，不都是你编码code最后不一样吗，所以他这个肯定以后的方式是什么，零是背景，二五五表示前景这样的话，其实一个手写字数字来说，零居多，对吧，那个255，什么之类，这种二级的肯定是少的，因为你大部分其实都会背景空白，那几个字母，那几个字123这那那点像素材才是有字的，所以说他把零作为一个背景，就很方便，你计算的时候很方便，所以东西特别不都没了吗，对吧，所以他就把二五咱们前景，这样的话，为了方便计算，，因为你连一张图片二八乘二八就是一个一吧，你那个依旧撞中间的几个像素点，对吧，可能就占了这么一个像素点，那其他都是零的，你根本不需要弄那么多数字，然后所以开始这么存的，所以我们要记住一下他跟我们平时来看的东西不一样，所以你就记得零代表的是BACKGROUND，然后255，代表的forwdground就是前景，这是他在这个数据的格式，然后我们就来看一下，这就是差别。但那个我们这个右边的图案，他那个decode的时候，他不是按照这个像素这个点decode的，所以，这就有点乱，所以我们不用关注右边到底说了什么，我们关心左边讲的是一个七，那么他其实在这个我们展示出来的时候可能就是这个样子的，我们如果按照灰度图像来展示的话可能就是，前景是个白色的会背景是黑色的样子，然后，前景就是二五五，背景都是零。但其实我们如果做就是CNN的话，我们知道在MIST里面，这个训练可以经典的方法就是用卷积神经网络。

比如说卷积神经网络就是神经网络，一般情况大训练的时候都会做一件事情就是之前我们讲过归一化，对吧，还记得归一化吗，之前由于没有归一化都溢出了，各种不收敛，然后各种找不着，loss，什么之类的，所以我们要做规划，把它扩展到就是零到一的区间或者负一到正一的区间，或者是什么，反正就是因为在负一到正一之间不能太大，然后这个，我们会把它归到什么负0.5，到正0.5之间，一般背景就是负0.5证前景就正0.5了。我这个区间激活函数也会比较这个是他激活函数比较，就是这个激活强度比较高的点吗，因为结果还是我们从正1.7到负1.7，它那个什么之类的图像，他这个节骨眼上最好的。

这时候，我们需要CNN的INPUT就是正0.5到负0.5。
 所以我基本上这个图像的记得，如果我们传递图像，我们说我们传照片，假如说我们在一个比如说一个任何一个，就是，比如说我们在C#上或者是PYTHON或者什么编辑文件一般吧，都是RGB格式，对吧，所以一般都是背景是白的前景是黑的都这种状态，所以你要把它变成了什么，前景是白背景是黑，然后这种格式，所以你基本上就得做个这个操作，让他从零到二五五的这个状态转0.5到0.5的状态，而且这个背景的背景要对上前景的前景对上对吧，然后就是这个黑白的这个状态要对上，所以我们来看我们到底是实际应用中，我们到底是怎么进行这样一系列的，转化怎么把这个数据进行一个归一化，这些一个正规化的这样一个方式的。

## 14

然后我们就来这个继续看一会能下载完我们再回来，那这个要是一个MDATA的时候，第一步肯定就是我们说的我们训练，我们做一个神经网络的训练第一步肯定要准备DATA，你没有BETA，一切都瞎扯，所以我们要准备这个，我也得知道我这想要什么样的data，它实际的到底是什么样子的，那我怎么样给他进行转换，其实，我们基本上训练神经网络的时候，大家都会默认用一些已经写好的深度学习的框架，比如像这个例子里面给大家举得，这种各种各样框架，我现在来做例子，其实我们就要知道这个这个框架它存dta的时候，它到底存什么样的格式，基本上这个两种格式叫NHWC和SCHW，应该有人知道这俩什么意思吧，请知道的请举手，哎呀，我终于觉得心里有点安慰了，知道的可能会在可能那个出去了，我先放小点儿，然后退过去大家是不是就看到我底下写的这个注释了哈，对就能看到这个注射这个NCHW，N叫什么，恩，就是NUMBER就是那个，有的时候数据，我可能，就是这个读漏的格式，可能我不想一个一个图片读，可能一读了就读一大坨进来，所以，这个C叫什么叫CHANNEL，CHINA什么的，就是刚才大家说的那个RGB对他几个通道的，那H代表什么，代表是这个图片的高度，W的代表什么，这个图片的宽度，所以他们在LOAD进来的时候，就是一个图片LOAD进来的时候他不同的表示方式，就是第一个肯定是最高的那个，假如是一个四位的矩阵，那最高的一般方式bach，因为好多图片，但是他们就是负一就是不考虑版本，或者是就是一那一个图片，一个图片的，或者说根本不考虑。

那第二个，就会有差别了，我们看这两个区别其实就是这个CHANNEL到底是放在前面，还是放在后面的这个差别。就RGB这个图片到底是R一坨，出来了一坨G出来，还说一个RGB出来，那请问这两种格式中哪一个是一个IP，那他load没进来的时候，他是一个，一个G一个B，然后呢RGB，因为一个就一个点了一个BAT的一个系列。这种形式LOAD进来的，它是RRGGB。两种，第一种是哪个，第二种是哪个。因为这个CHANNEL最低层，所以对立的次数最多的，然后底下看到的后面就是什么，就是一口气把所有R，一口气把所有B弄过来，在这个这个四维的矩阵里面他在这个维度越高，因为地位高的时候，你就越后面展示出来，对吧，那这两种格式的区别，一般情况下，CHW的一般有一个框架，最开始做图像处理的时候大家基本上都用到的这么一个框架，所以face别人检测什么的，大家一开始的时候最最经典的老成员基本上都是咖啡框架起手的。

然后剩下那些框架基本上都是第一种，，所以当你做不同的框架的时候就遇到了一个这个了，data的时候要怎么转，否则你就训练他的结果都是错的，那他们两个差别是什么，这种这种CS后面滴看到在后面局部性更好，因为什么他一次把一个ID露出来，其实你就可以直接转一下就可以算出来，整个就直接把它转成灰度也好转，对吧，你要这种的话，你还得把每一段取一个，那跳着去访问这个词空间，所以除了咖啡以外，剩下的都是这种，然后他主要是，就是仿存在这个局部性能，而且开始领域高用CPU处理快，那底下这种，用这个扩大GPS哪个更快，然后我们只要对她和麦克之后还要知道一个对他的认知，我这data到底是他什么样子，它的原始图像是零到二五五的，但是真正我们要做的时候，我们要把它变成负一到正一的这样一个区间，然后并且负0.5的值代表的是我们之前的零，然后那个正的代表我们之前的那一个二五五的那个值，然后这样子的一个DATA，所以我们准备data               的时候，我们就这么准备，如果我们平时用的这个，那个RGB格式，我们回头看一下怎么进行处理，这是第一步，然后我们来举个例子，这就是coding从哪来的，这个code就是我们那个从这个那个截取的。

那在EMS上，我们说那个DATA都是从0到25255这样的处理，所以我要把它变成负0.5到正0.5就是我的这个先训练的时候，我要做这件事情，首先，这个第一个就不讲，那个知道这就什么打开一个文件，然后把文件都读出来对不对，首先读了16个字节，大家知道想起来的16个字节是啥，对对那个头，现在有一个对吧，四节魔术，然后train、test，对吧，然后再有四字节保存了。

所以我们基本上这是一个，超级简单的预处理，这是预处理过程没有用到什么特别复杂的东西，一般，我们做预处理的时候，就是图像应是一个大的图像，这个这个图片的分类的一个那个数据，数据结构非常大的应该比他做图像转换的时候比这个复杂稍复杂一些吧，它有很多不同的这个归一化和正规化方法。

那第二个，在看一个图，这个就是C#的代码，大家不用明白，只要跟着我就是认一下都干啥就行了，这个C#的头像是干什么的，这个是我们做的一个节目的APP，这个APP，要怎么着了，在一个手写板上，或者是你电脑上，一个是手写的一块儿里面你就手写一个数字，然后，他来把这个数字识别出来你手写的是什么，我们做了这么一个应用，但是你手写板手写的书。这首先第一个他是RGB这个格式的对吧，所以他的编码跟这个原始的就不一样，然后，你要把它转成，CNN的这个输入input的这种格式要怎么转，那第一个肯定也是要读像素，对吧，然后读出来的时候我要把RGB取个平均值，所以把RGB都拿出来，这就是看到了放后面的好处，然后你就读出来，这就是快，然后去完了之后，那我们要把他除以个二五五，0到1之间，但是问题在于他跟我原来数据差别在哪，那原来的零是什么背景，对吧，然后那个225是前景，但是其实我们APP会发现吗，那个那个黑的我们手写的时候背景都是白前面黑，那黑的不是零售的全部有数字有字的，所以你要给他倒过来怎么办。人家是用二五五去捡对你就用什么0.5减去这个这个给他倒过来黑白就翻转一下，然后他也变成了这个样一个格式，如果大家不明白这个的话大家也可以自己再想一想，然后这样的这个图像处理就结束了，所以这第一部分处理的部分，大家都明白吧。

然后第二个，就是datausage，我这个这个数据我已经处理好了，然后怎么使用，一般情况下，我们对数据进行属性的时候都会分三类，然后要traindata，一个叫TESTDATA，这三个干什么，traindata肯定是要训练，训练好了之后，就会得到一个固定的，出来一个model。需要一个验证集好了的，因为这个验证集的东西放进去之后，然后数据那个emd放进去之后，然后就会跟那个验证集进行一个验证，如果你预测的是零，那那个验证集那个那个那个光处死那个真值也是零说明你这个就是对了的。那通过验证你就可以知道你这个训练的这个东西，有多么的好对吧，就是训练的好还是不好，如果不好怎么办，你要改模型或者改算法或者是怎么怎么看你到哪个问题了，一般我们需要一个验证集 。

再有一个测试集是什么，他一定是不能够重复的，那个测试集就用来测试你在其他的情况下是不是OK了，因为你在训练集体训练的特别好的测试地方特别烂，就是为这个模型了，那个就是一些不该考虑的可能也考虑进去了，然后导致他的泛化能力特别的差，你可能需要调整，所以一般情况下，我们对他使用就是三个集合，一会儿来我来跟大家从一个PYTHONCODE上，我们来看看这是怎么来划分的，然后，那地下一步怎么我们都准备好了就训练了训练，其实我们就要调的一个模型，对吧，，其实我给大家来讲两种方法，因为EMS实在是就是太简单了，所以一般他一个三层神经网络就能得到迅速来，所以，第一种方法就是什么，我们根本不需要特别复杂的一个东西，我就是全连接。  然后，如果我们三层的神经网络，我们把输入不算一层的话，他就是三层的神经网络，第一个就是input，就是28乘28=784对吧，所以，我们看到第一个第一个这个INPUT，这什么，784这个，这个兑现84个班，然后，这个就作为一个用户的就是一个图片进来了，然后他中间有两层黑灯链，然后黑的那个做了什么事儿，首先我们是做了一个叫什么，其实他是一个线性的一个工作，C等于X加B的一个活儿，这些都加进去，这些为了所谓的都加进去，就是我们之前学的那个最最常见的一些这个知识。然后底下那个relu，是一个奇函数，然后把这个线性的东西变成一个非线性的东西。然后第二层黑灯链，就是也叫隐层，除了输入层这些都要隐层，那这个隐层的。第二层也是一个，线性的再加一个激活函数，也叫LOST反函数。在这个分类过程，他即是LOST方式优势分类方式，然后他也是奇函数是吧，这个意义一个函数的功能，然后给他做一个SOFTMAX取一个最大值，那就是最大的这个东西，就可以被，这个就是最大的就是他的预测值，最后只最大的一个MAX的一个外流，就可以看出他最大的是什么就可以知道了。

## 15

第二个就是什么，我们要根据这个这么简单的一个东西，我们给大家介绍一个就是非常非常通用的一个网络叫什么，那个也是一个就是基本上大部分东西就是，这好多东西都能发出的一个卷积神经网络，我们用这个MNIST的这么简单的一个例子，我们来给大家来介绍一下什么叫卷积神经网络，然后首先，我在想转向烤炉，所以CNN，简写CNN basic，卷积神经网络是一个什么概念，我也不知道这个是真的假的，就是大家就是觉得什么，比如说你看一张特别复杂，图片，我应该摆图片的，没有摆。就是一行一行的看什么之类的看他理解他，你也不是有很多的时候，我们可能这个大框架的，我们可能会觉得少可以下一眼看出来，但很多那种东西特别大的时候，其实我们有一个感受，也就是你的眼睛，只能看到一部分，然后你抓住了一部分特征，对很快速的把它拼成一个图，然后让我来看你之前可能解决他的缺点什么，我们刚才看的时候，那一个，就是MNIST其实非常非常少，这个训练参数一共才784乘以128乘以32什么之类的那种就是没有多少，大家觉得这个参数好多，对吧，那如果，如果他是一个非常非常庞大的一个图非常是那个村的图案片材只有一个，要三个才能然后再弄得非常大，你可能就训练的参数就会非常之多，那其实这么多才可以训练不见得效果好，但是训练的这个时间成本，各种成本其实都很大。

后来发现咱们的其实，人不是那么干的，那可能人也不会小看小看，反正目前大家都说这个可以这么一个感受野的这个概念没，就是指一开始只关注一个大图片的其中的一小部分，再给他拼成一个大的部分，然后，这样的话你训练每一个小的特征的时候，其实你付的代价是很少的，但是把小的特征和在一起的时候，就是就进行了一些优化，所以就做了这么一个操作，它每一小部分单提出来，然后，去给他做一卷积计算，然后去改变它的特征值就提取他特征信息，然后再进行一些就是，这个计算，然后我们讲那个卷积神经网络的基本概念就有这么几个东西，第一个叫filter，然后第二个叫深度，然后第三个叫Stride步长，，然后那个然后是padding。

然后这里这几个概念分别干了什么，就是我们说我们有一个感受也，他可能就是这么一小块我，就想感受这么点东西，那这个要感受这个东西，我能够用一个东西来感知这一块儿这个小东西叫什么就叫filter，这叫这个过滤器，我把其他的屏蔽掉，我就过滤这一点，然后他过滤器，他其实有一个深度的，那我要一个过滤器，我可能只过滤出来一个比如说我要过滤出来一个猫什么之类的，那我可能那个第一个过滤器就过滤圈一个圆，或者第二过滤器就过滤出来了一个边形的弯弯的，那么甲方过滤一个五，可能第一个过滤器就过滤这个横，然后可能下一步离心过滤器树，然后在下一个过滤器能过滤哲，那这样子的话，我也可能把所有的过滤叠在一起才能叠成一个五，这时候我们就说他有多少过滤器过滤这张图片。

我们就要过滤器的深度，那那个比如要过滤器，一个横版的我设过滤器，那个过滤器可能只有这一点上都是以数字，其他地方都是零，为一的那个部分可能就被过滤出来，也可能是这种排列格式的，一个横线的部分就能被过滤出来，所以这种这种样子的形式，所以，我们知道过滤器多少个就是深度，也可能不是固定在这儿了，他可能感受整个图片，所以你要不断的移动你用多大的距离去移动它，然后每次是移动三个格移动五个一共七个格，移动过去终将跳过多少个你忽略不计，这个就叫什么步长，然后还有padding，其实就是说，这个过滤器可能你是准备从这儿开始过滤，而有的人可能觉得这样过滤的时候我可能这个特征是在中间位置，那么偏上位置，怎么办。 有人想从这过滤的时候，怎么办，从第一个开始就把它处理掉，那其他地方都不灵，不灵，因为你真的那个图片没有那么多，所以你要把这个图片变一下，这个就是更大了，所以这个怎么办，这个padding要把其他地方都填成零，那再拍定的就是填零，那是不是要padding这件事，就是我们不同的算法决定的了，有的算法就让你拍给他，比如说把这个过滤器就移到边角上都给你，你就不够了，比如说，对，一会来讲了然后怎么处理，反正就这几个基本概念吧，然后我给大家讲一个例子，因为大家听这个概念，是不是有点听蒙了，现在就是不太不太明白讲什么是不是有点这个节奏又不知道为什么，因为谁知道这个CNN的了解新人的请举手。

这个卷积的概念是一个数学概念，具体请自行这个学习，对这个这个到底是怎么去变化，其实减就做了一种变换，然后这个这个变换的方式，就是他其实跟数学这个变化也不太一样了，但是大家还是用了这个卷积这个概念，然后这个数据里面那个卷积是怎么怎么去感受的，然后怎么去变换的一块的，大家自行自自行那个查找，不解释了，其实我也不太记得他那个什么搞得了。然后给大家这个简单的来算一个东西阿，我们我就瞎写，看大家来算怎么样，那简直神经网络是怎么了，假如我现在有一个图片， 这个图片我就随便借不是图片，我就把一个东西我给她简单的感受一下   ，我想想就随便瞎写了，我觉得我应该是有例子的，我上网搜一个例子，可能会比较好一些，我自己瞎写一个数吧，也不太好算，我给大家说一个例子吧，看看这个能不能搜出来，如果做不出来我自己瞎写一个队，怎么这怎么弄的卷积，GOOGLE搜不了是吧。

这个图解看他能不能讲到这么细，其实大家可以看到你想了解这个东西，其实很方便，网上到处都是例子，对吧，然后你想了解神经网络也很方便，这就是天下文章一大抄天代码一大抄下图解一大抄。你把那个网你把网址发上来，我从这就能打开了，其实是我想让大家来做一下，好，你再给我发收到了我们每个人准备好笔纸来练习一下。
这个图太大了，我在弄小点对这先不要动画一会儿动画，把大家给弄蒙，这样可以吗，能看到哈，这个什么，正好就你看他画了行比我画的好一些的七列的，就是我自己划拉这些一堆零一什么的，大家也不好算回头，那个这是一个图片对不对，然后这种东西叫一个FUTURE，然后他什么，他叫什么，就是他就有两个FEATURE，看其实就是什么，其实就是权重，对吧，那这个权重是什么样子，是三乘三乘三的权重，一会我们要解释这个FEATURE啥样啥样的一个你，一个图片怎么RG吧，这三个通道，他把三个通道都有各自的这样一个FUTURE的一个过程，所以他就是三乘三的filter，就是把这个说成糊在上面某一个地方，然后，跟他算一下什么WXZ等于WX加B，那我们所有的一切都离不开这一个最简单的对吧。然后把所有东西加上加在一起，然后做了这么一个操作这个卷积。

## 16

这个数学概念不太一样，这个我们整个神经网络里的卷积，那我说了这个三乘三的这个东西，这是一个filter，我现在已经第一个filter的第一个这个CHANNEL来看，这然后叫什么，就是算的这一块对吧，三乘三，然后，他就在那如果他再步长为一的叫什么，他就怎么着步长为一，它步长也分两部分，一个上下一个左右，这样的一个三乘三，这样能乘上的话吗，不能，他就变成一个这样一个三乘三，然后转的步长为一的时候，怎么下一次会移到到这儿来，刚才错了一个。如果你不超过二怎么办，那下次移到这儿来对吧，然后，他讲说他不想第一个filter出来了，第二个那个深度出来了，有两个第三个步长，他的第四这个什么意思，你看这个图片周围填了一堆零对不对，假设他是一个填了一堆零，其实他可能这个图片就是切成其他没有填零，我假设假设图片是个5*5的填零了，为什么，他想不是从头开始一，他想从这开始一对吧，前四个填零，然后这个拍子也分为上下左右四种以后我们来看这个就是每次你拍这个多少，比如有的有的地方一般大部分什么左边一行右边一行上面下面补一行，有的他不是，就是这样一个不对称的排列，所以在计算中就会增加很多的麻烦，那我们现在不考虑这些复杂的情况儿，这个里面没有排列吧，这个图片是七乘七的。

然后从第一个三乘三开始做的，那这个卷积做了一个什么操作，就是第一步filter，他就有三个产能分别对应的这个图片的三个channel，从头开始就点击，然后这样卷积一层，然后他的步长，上下步长都为一，也就是说他左向右他就每次移动一个步长，向下每次移动一个步长，就算出所有的值，然后作为一个OUTPUT，然后在这里面我们就算其中一个，他现在算的是，这个对右下角的这么一个，那我们，唉呀，我要大家算右下角的这一个，就因为这个过程那这样的验证下对错对不对，好，那这样的话大家来算一下怎么才能够得出第一个output。

现在是一个七乘七的现在是一个七乘七的图片对不对，然后给了一个三乘三的一个FUTURE，然后，我每次STRAIGHT的等于一移动一个补偿，然后，基本上那请问这一个七成七的INPUT变成一个OUTPUT的时候，那个APP的大小应该是多大的，就几乘几，是五乘五，算了下，为什么是五乘五的。大家知道这个怎么算，对七减三加一第七个吗，移到最后一个，所以还得加上这个一，然后后面还有四次，再加上这一次就是五次了，所以7.减3加1，7是input长度，3是 filter长度。然后，那个加上1，对吧，第一个了，然后，其实这个过程中，他的还有一个就是还有一个问题就是什么，你现在步长是1，步长是2呢，对就不一样了，而且单数跟双数也会不一样，有的时候你到最后你可能双数一双一到最后一步到底，你是为什么，有的方式不一样方式，有的可能最后不够的，就给他填上一行移过，直接把后面滴所有都砍掉，这个不同的这个算这个卷积的方式不一样，所以这里面，在这个例子里面是五乘五。 然后每个框架，其实大家看的时候padding最后的OUTPUT格式，都有这个不同的算法，那个大家可以那个自行来那个了解一下，比如说有的是七减三除以二加一，除以这个SURPRISE什么之类的，还有把放在哪儿的，就是每一个框架方式不一样，就导致他们最后的结果就不一样，经常他们俩做转换的时候就费劲，在这里面我们步长是一很简单，就不需要这么费劲了。他的input是五乘五，然后PAD了，加了一个一，对吧，大家聪明，然后步长是2。这就是一个五乘五的，然后加了一个padding，然后三乘三的，然后，filter是2，不就对了吗。
所以这个卷积神经网络已经把这事解决网络已经把大家弄蒙，是不是。然后我必须得用一个这种复杂的才能继续往下讲，要不然我后面概念，大家听不懂了，对他其实卷积的概念其实挺简单的，你只要把这几个概念弄弄对了可以了，对吧。然后每个过滤器什么，是三乘以三乘以三的一个矩阵对吧，那第一个3是什么，是H.第二个3是W，第三个3是什么是C，前面可能还可以有个N，但这里面就没有，就每次算一个，我们这个格式，output不就是三乘三乘二的吗。
权重不同的表达方式，我在现行的里面的B那个权重就是那种格式表示的，那么卷积里面权重B以这种格式表示的，那你的input是什么是一个图像，那就是按RGB格式，不是一个图像特别的东西，就别的格式，但是经过卷积的时候会变成一个输出，就是什么样子的，无所谓。那你可以这么理解，我自己瞎理解的，我不知道对不对，我理解的是这个样子的，输入是一样的，其实是一样的，然后，对着一个参数。但是你这么这么理解吧，你这么能这么理解不太好，其实大家都这么理解的。一个input的对一个output的，然后中间是一个。 你看，大家看神经网络都用这个图，这个图是一个经典的图，看到没有，是224乘224个输入。他做一个这个图像分类，他不是数字书写数字28乘28最简单的，这是24乘24乘以三通道的手写数字28乘28乘一的对吧，所以很简单了这24乘24乘三的，然后他有那个四他这个filter，是一个11乘11乘三，因为它是三通道。所以是11乘以11乘以三对不对，然后，那每一次都得过一个11乘11乘以三这么一个你才能把这个三通道的东西全都给呼上，因为他96filter上，所以大家都是这个方式来理解它，就是11乘以11乘以三，然后再乘以96的深度，所以最后输出的时候就是一个96层，再这个256层的就是2526384348256的，然后是这样做的，所以这一个经典的，所以我们把他给他细化，然后大家理解一下卷积怎么做的。就是刚才那一个大叫两个filter出来的什么了吧。就是两个深度为2，这96就是96filter。我们的就是这个两个深度事儿，然后这样做的，刚才这个图没打开。你看这个过滤器的意义在于什么，你看他前面的过滤器，就是你看他不着过去就不同的的意义在哪里，它不同的过滤器，应取值不一样，比如有的你还有他的图像一个图像，其实很复杂对不对，他为什么用那么多过滤器就96过滤机256个384个，那么多的过滤器，过滤一步骤，比如这个我们过去这个这个角度的值，这个过滤这个角度。所以你看以前我们学那个就是这个图像处理的时候都看到很多种不同的角度，其他人不知道这个层度上有值，这是第一层最基础的层，只过滤线条，然后可能到第二层的时候会过滤片儿，一个半圆一个椭圆，然后比三层的时候过滤别的，所以这样的话，你把每一层都堆积起来，然后最后他就过滤成什么真的能够识别一个这个狗来了。每一个由这个狗的这个圆的眼睛，狗这个边框，这些都过滤出来，那为什么这样的过滤出来，那个大家也说不明白，反正这样就是可以。

## 17

所以说把这个特征匹配的就变大了再加，所以不是更匹配的值都是零了，对不对，那小，其他都是零，对，就拼起来，而有时候你不需要一些细节，这你不用每一个都特别细节，所以他有一个叫池化那个操作就把他那什么一个一个扩大对一个扩大化，我们先把卷积层搞明白，然后我讲池化层，什么之类的这些东西，对这个卷积神经网络，这这个看出来了吧，他这个过滤器，其实顾虑一个特征的过滤器，只能过滤一些些直线，然后关于现场只限高层的关系可能会过滤一些特征一个别的那种神经网络，深度神经网络就是每一层的时候，都不一样的，当中还有一个叫funturn就是这个就是优化训练，一般funturn时候就会固定前面那些训练草的那些，只训练最后高层的这个特征，因为他低层可能差不多对吧，你过滤的直线或这个线条可能那个位置已经训练到最好了，你不要再去训练过滤直线顾虑这个半圆的了，你可以需要过滤高层的信息训练，眼睛，鼻子嘴，什么之类的那种了，所以这时候就是神经网络有好多这种优化的方式，就是根据这个卷积神经网络这个过滤器的特点来的，那这个第一层过滤器特点就过去的东西就比较基础了，高层的时候就过滤的就比较就比较深，所以他这个层次，你看每层过滤完了东西就不一样了吗，当然，这个这个可能也不认为一直过滤这边这个对A什么的到三的时候可能就过一些纹里了八到15的时候，他可能就是一个PAD就能过一到这个一部分了，对吧，然后到最后的时候，他就能够去分类。可能就把它分类成了多少个这是什么东东。

这个图大家看明白了，这个网络就是我们经常见到深度学习的网络，但如果我们刚才不讲那个东西，你看这个网络根本不知道他在干什么，对吧，所以刚才我们讲了刚才的filter概念就是弄那个什么东西，大家才能够知道这个是什么，那现在我们一个个半小时了，我们可以先休息一下，休息一下，大家先想想。

这个特别简单就是一个五乘五的矩阵对吧，然后，都回来了哈，咱们几点结束来着，那个还能还能还能讲，这是一个55的矩阵对吧。filter是三乘三都会用到的，然后，那个STRAIGHT步长是一，所以每次都往后移一个，横向步长是一，纵向步长也是一，然后深度没有，所以它的深度的补偿就没有，所以，这只是一个就是对一个一就是最简单，最简单的了，然后怎么算，现在底下就有一个这个动图，你看这个动图是怎么做的，我等算完了，他会在第一个，他不从头来了来了，能停吗，我就不截图了，就这样了，用这个上头那一个，这个01101010101这个东西其实什么就拿他跟他每一个元素相乘，然后再把所有元素加在一起，然后得出这一个数，所以你看这个过程的时候，为什么在五成五变成三层三，对吧，他用的是一个五对吧，减去一个这个三是他的那个filter这个，然后除以一个一再加上一个一看得多少，然后这个是那个filter的那个一个W的宽度，然后这个，是这个input的宽度，对吧，宽度，然后这个in就是一个排名，所以就是吗，然后除以一加一就是三所以这个输出格式就是三，所以他却什么input的W或者H减去这个filter的W或者H除以一个X加上一就算出来一个OUTPUT的W，然后H同理，对吧，就是
in的H减去F的H除以X，加上一，这个公式就出来了，所以这个输出的这个宽度跟输出的高度，大家都能够算出来了，就是这么一个公式，然后是不是根据这个算就很简单，大家给我算一下这个四是怎么来的，第一个四左上角的四，笔算一下，然后咱就看这个对对我可以看这个咱们就三乘三，行吗，反正很简单。然后一个叉的部分几个，三个对吧，然后再查一下就是四个，然后，再查一下，是两个再叉一下，是三个再叉一下，就是四个吧，就是他随便举个例子，讲究一个带叉的，这个这个图就出来了，很简单，对吧。因为所有东西只要一乘以零，不就是零了吗，他不想提取做成这个filter就放零，他想提取的特征就是放一然后给他家就准备上了就可以把这个这块特征对加大了增强了对吧，对就增强。

这个概率最大一个OUTPUT出来之后，然后对对概率最大的这个然后就什么这最大的其实是五个12345，然后他把他这个特征能够提取出来，到底跟他有多match，所以这个东西就提取一个这么一个特征，所以把他忽略其实只要看这，边上都是零都不要算了，因为你多少数乘以零都是零，所以只要看见五个点，然后就出来了，这是一个单层的是不是特别简单，然后后面滴一会我们再根据这个图来看，池化是怎么搞的。来算第一个OUTPUT跟着第一个filter三个维度，这个该怎么算，这个我们看了一下他的padding是他一定是一一上下左右全都padding一个一对吧，然后，其实这个在不同的表示里面不同的框架里，他也表示是不一样的，那我就先以这个一一这种方式来表示，然后那个这个都padding了一个一，然后这个filter我就输一个三乘三，其实他是三乘三除以三对不对，然后input七乘七，是五乘五。因为她加padding了对吧，所以input的是五乘五，然后，这样吧，算第一个filter，然后把这一个5乘5乘三了这一个，这一个图片通过FUTURE出这个结果是怎么做的，然后我们叫人上来写出来。我们说这个BOSS什么是根据一个神经元就有一个BOSS对不对，所以，这相当于两个办法，如果按这个算的话大家就算成两个神经元的输出了 。

## 18

我这样算的话对一个BOSS对应一个输出，然后BOSS什么，是把这个东西所有东西就是一个一个这个filter整个这个算出来之后，再加上一个BOSS可以了，如果你要boss0和BOSS1的话，就算是两个神经元就算是一个filter，对着一个神经元的，如果按照算一个神经元只有一个BOSS，对吧。一个是要是最后W加B吧，这些都是X的过程对不对，只不过用另一种方式最后才加B，大家可以算一下，一会儿找人上来算。
说明大家都已经算明白了，我那个第一个细节就不用看了，就是基本上就细节都列出来了，其实这个结果就是对的第二个其实就是怎么说，把他呼上来，只有这一个位置是一，这个一对的零其实就是零了，对吧，这个这个呼上去的时候，也是他是个一岁也是个零，这个呼是二就是他是个二对应的就是负二，然后再加一个零就刷了对吧，所以就这种这种格式说明大家都已经算对了，所以这个已经是OK了，大家知道卷积到底是怎么弄的了，
然后这就是一个卷积的过程，那做完一个卷积了之后，其实我们看应该是个神经网络他训练的时候，他卷积完了还要做什么，他还做一个，其实有好多东西，会做好多操作，这个MNIST的太简单了，所以有些细节没有搞，比如说他的没有做的，我们说，一般情况，这个这个神经网络卷积层训练完了之后还有一个叫batch的就是这个，批量这个正则化，批量这个正则化的操作其实就是为了变成正负就是变成就是正则化，让它起到中间就是，负负得正的差不多的最后一步的时候可能就能够取出这个正值副值来，但是这种就不需要，所以，因为他太简单了，因为我用的这个操作，所以他卷积神经网络疑问就是我们看他的怎么实现的，这里面是怎么实现的，我们把卷积层这块说完了，基本上大家都明白怎么回事了，那这个基础概念第一个filter，所以，一维filter，他就会弄成一堆线就是一个维度，就是在线上进行划分的。二维，就是一个矩阵对吧，我们经常在矩阵用的都是二维的。那个三维的，就是有个这个深度对我们现在用的都是二维的，然后我们刚刚那个filter也是二维的对吧，他是个二维的，对这个是他的BOSS最后的这个偏移，跟这个filter没有关系，这个所有的算完之后才加了偏移对不对，然后这个filter结果就是就是基本上这个就是什么，就是他的这个有多多高，对吧，就三个我们三乘三的，H就是什么三把一个三乘三的filter。刚才那个CHANNEL是3对不对，最后你出来的OUTPUT是多大的值就OK，我们那个出来的，不就是一个那个是2，对吧，所以说就是就什么就是三，三乘三对他真是这样的划分的这个filter，然后深度，刚才我们说有两个filter深度就是二，然后不断的stride就是他的步长，步长他也分为就是你要一个batch的数据，其他基本上我们这个一般都不是，都是零都是都是负一，然后就是说不算batch，然后那个H，就是步长的，这个你在一个大filter里面，一个大的一个图像里面，你向下移动，每次移动多少个你的filter上下移动。
就这个H，那向右移动多少个就是这个W，然后CHANNEL你到底是几个呢的是三个，比如说有50个，我每次向后一两才能其实没什么中间差的不算，这就是他channel移动多少补偿，所以他一个立体的，你发现了向下向后，我们一次移一个，如果你猜到算一的话就是每一个CHANNEL都算上对吧，所以对所以我们的这个channel是什么，我们算的，其实在这里算的话那个是不算的是负一，然后H是二，那个W是二，然后channel是一，我们刚才那个就是这样子的，对不对，我们又每次移动俩，我们向下，每次移动两个，刚才我们没算对吧，然后我们三层每一层都算了，所以这个就是一个一。如果只算第一层是二是这样子的，就是有这么一个概念，所以，你得知道这些东西都是怎么表示的，然后到神经网络里面才能看出来，为什么要这么搞，然后，这里面就是一个例子，就是说所有填充的地方填0，最后padding，最后padding的方式有很多种，有这个就是SIMULATION什么之类的这种不同的padding，我先把概念给大家解释清楚了，然后我们一会儿去看这flote是怎么实现的，所以说在这里面，虽然他的时候，刚才走了这么一个东西，你把input的放在第一层做了一个卷积。卷积完了加上一个BOSS，然后这个这这个东西都是什么都是input跟output到底是多大的，一会儿，我们就来算一算他最后到到底应该是多大，因为我们最后这个我们去设计一个模型的时候，我们说我们给他一个input的，知道output是多少才能设计这个模型，所以我们就来算算他，就是那个激活函数对不对，我们把这个线性的东西，WX加上B之后，还要给一个激活函数，然后再做一个maxpadding，就是那个叫最大池化，有很多种方式，就是这个概念。

我刚才那个图在哪里，这叫池化什么的，你看，其实我们说这个图他他现在很大还是一个四乘四的，但其实有的时候你不需要那么大的一个特征，你可能你不需要取这么细腻的特征，对吧，你每一个那么点是什么，你就取出来，可是我们只在乎在一个大范围内，它的特征，具体表现成什么就得了，不需要这个细节每一点是什么特征，对吧，我们有的时候不需要那么细，所以，在为了让我们的那个预算能够更简化，我们的这个矩阵维度越低，其实运算量越小，我们越能简化，一般都会做一些池化的操作，比如说我只需要关注这四个方向到底什么特征，所以不需要关注某一个点什么特征，那我就可以怎么把这四个方向变成一个池化的一个操作，让变成一个什么更小的一个维度，那这个池化就叫二乘二池化。 我就把二乘二个，对算成一个和最大值对这个池化操作有什么，求最大值，求平均值，然后有不同的这种普通的方式，那我想求这个特征里面最大的那个部分被体现出来就作为整个这一片区的一个表示，那怎么办，我就在这里取最大值，所以这是一个二乘二，池化就会有很多方式，有这个padding他有这个池化的那个大小，然后他有padding这个方式，这里面是没有任何padding的，然后，那个他就做了一个2乘2的一个这个池化，二乘二的灰色正好四个，怎么上下左右呼上了。这其实不叫，这个也不叫，也算过滤吧，也算是其实这个哪个地区哪个特征最大，你不需要知道那些小的特征是什么，你知道你就关注到这一片的核心对吧，我刚抓的核心特点，所以这一片最大的六我就可以把它作为这一个片区的一个特征，这个是8，作为这个padding，这是34，然后放过来，这样的话，其实这一个最大值能够代表这一个片区的一个特点，然后就是做池化，为了简化操作，而且为了我们取得特征的时候不需要那么细的特征，然后就这种事做池化。

所以就是不同的这个处理的方式不一样，对这个叫最大池化，大家做池化的时候就是大部分的操作还。中最大值话来增大这个特征的这个这个这个特点吧，所以最大池化被经常用的一个方式运算，我要在二乘二怎么怎么样，其实也不算是过滤器，你也不跟刚才那个不是一个概念，这个概念什么，我这片区我不想知道每一个片区的细节，我想知道这一块儿就可以取一个代表来代表这一片就得了。这里谁最大我就取谁，那我当时怎么划分这个区域，对吧，我每个片区取一个老大，我可能化成二乘二组的一个小片区，我可以换成三乘三组一区我，一个四乘四小片区对吧，那我现在想把它什么，变成一个二乘二的小片区，然后每个小片区取最大值，那怎么办，所以这个没有什么那个步长的概念，他觉得二乘二的话，乘二乘二这么多的分割一下。我其实为了求特征对不对，我取得最大值，其实就能表示这片区的特征，我干嘛要算这么多。这个不叫卷积层，这个池化层，不同的层了，刚才卷积层，我们已经算完了，那他是上一个卷积层的前面和下一个后面。

## 19

我们有很多的方式去优化这一个网络，优化这个网络方式是什么，我们发现我我卷积层，得了一个输出，我这么计算，也可以，但是信息量太大了，我不需要这么细，我就把他怎么样提取出每一个部分的最大值和什么能代表这个的，然后就像一个小的，这样就很方便了吗，算小的快，用的这个参数少，所以就加了一个池化层。这其实都在大家不断的优化过程题的不同算法，一开始的时候没有人提卷积神经网络的时候都是什么，这个复利CONNECT，然后就是这种叫全连接全连接层，对吧，后来我就提出了卷积，然后优化了卷积效果很好，不用全部的感受那所以卷积的时候参数也很大，我们刚才说的那个224乘224，那个是基本的就是里面图像基本达到2424乘二四乘三你想这个多少个参数，你后面再跟一个对吧。那你那个29、96分左右，很多参数，那时候我们说这操作也太大了，算起来特别慢，然后就会发现，我可以再简化一下，就是我跟你一个池化，每段取一个值不需要整个的细节，然后这样子就就变成了一个池化的这样的一个方式，然后这次做了一个就是区重点抓重点的一个操作，然后把它变小了，让我们的计算更容易了，那你下一步再算卷积的时候，你不就数据量就小了吗，所以在这里面这个神经网络，做了这么一个操作，这个神经网络CNN就是这个最简单的MIS实现的，就是那种，就是一个卷积层，我们每一个程序，一个二维卷积层就是FUTURE是个二维的五乘五的，这个是一个我们看代码就知道这是一个二维卷积，加上一个files时对吧，那个偏移加上一个然后做了一个激活函数，然后再给他池化化一下。

你下次卷积时候你就更好办了，然后那个然后再加一个BOSS，然后再做一个relu再做一个，你看其他结构都差不多，这是一个子结构，它把子结构形成一个不同的你要看那种更深的神经网络，比如说VS152152层的这个网络那里面数据好大，但是算起来也很慢，但是你发她那个每个子结构都是一样的，它就把子结构篇拼在一起，算了好多个子结构，子架构拼一起就可以了，然后reshape，因为它这个卷积的两层卷积后面还要跟一个全连接，因为最后变成一个十维的吗，一个维位就肯定要全连接给他拍成一个维位点的，这个把一个框框那么大的一个深度宽度的设备应该长长的然后到最后做一个那么向量乘就是这个就是那个全连接了吗，然后加两层全连接，然后最后softmax给个结果，就是取最大人就可以了，你去这个最大个MAX就是你十个里面取那个概率最大的一个就是一个结果，对吧，是这么算的。

然后我们一会儿的时候，我们要算算我们根据代码，我们来算一算这些东西到底他OUTPUTSHIP都是多大就是我过了这些之后，这个数据变成了什么样子，他长成什么样了，我们基本上能把这个分这个经典的方式算了MV的给算出来了、OUTPUT让大家算什么来的，现在是还有两分钟12点了，我们可以先吃饭，大家消化消化，然后下午我们再算。

## 20

我们用卷积神经网络去训练一个MNIST的那个模型造怎样的标志，我们第二部对吧，我们说训练模型的时候，第一步是准备数据，第二部是构建模型的第三部就开始train了，然后处理完了之后我们就去infrence，然后去给他做应用，那模型构建起来了，这就直接就不同网络吗，你设置一些参数就能进行训练了，那我们一会儿我们结合这个代码我们来看一下到底这个模型这个这样一个的这样一个网络是怎样搭起来的，然后代码里怎样实现的，然后怎样训练的我们跟这个代码来看这个代码是什么，那个就是这个代码。



## 21


那有的人，觉得自己写一份子太费劲了，所以有的时候我们我们就给提供了一个什么代码自动生成一个方式，对这两种方式，第一个就是你自己写一份code，第二个就是那个自动生成一份code，然后我今天留的作业，我就先留下了，那个我们刚才看那个fuliCONNECT的时候就是这个FC的这个代码的时候，他就有一个inference code对不对，我让大家看了英文课，其实就做了正常计算两层累，然后把那个变量为进去，然后基本上两次就出来了，那现在，这个code，他现在没有这个inFRIENDS，但其实你在网上搜，就可以收到。

## 22

那我留的作业就是，请大家用PYTHON写自己写一个INFRIENDS的扣的，然后，目的是如果不管你你可以自己搭一个这个APP，那个可以有一个可视化界面，或者你不想搭可视化的界面，你最简单的方式就在命令行传进去一个手写字体的文件，短时间到哪找都行，然后输出的时候输出什么，你这个预算值或者你自己弄一个程序自己写一个东西，然后完成一个工作输入一个零到九的一个图片，然后，输的时候，你就得到多少，这就有 几个问题，第一个问题是下载问题，我们说的是28乘28的你手写图片不见得28乘28的，你怎么样改变他reset28乘28的一个水平，然后，你再把它喂进去，然后还有第二个就是什么，手写的时候有可能那个图片上JPG的格式，但是你最后那个因为你这个那个EMS要的是这个灰度图像，而且是负0.5到正0.5之间的图像，你要做一下这个处理图像预处理的操作，这些都要确定，然后再encode进去，然后给我一个正确的输出，这个作业，大家可以互相商量，如果一个人写不出来，对，可以这个互相商量一下，这个集思广益，每人写一段什么之类的和一下，我觉得都没有问题，我觉得一个人能写出来。那我就给大家来讲讲我们怎么自动生成code，这个就是从现在开始往下的内容，大家就权当听一听可以，从现在开始往下那种全场听一听，刚才这从这网上的内容，你可以多多好好过一遍。

## 23

第二个是MNIST的一个扩展，其实刚才我们那个只能识别一个零到九的，没什么意义，对吧，那真正我们想做的什么，至少能够识别个3200，对吧，除个五，然后那个根号四之后能够二什么之类的这种。那个MNIST就一些扩展的东西，在我们刚才那个AI就可以省里面还有一个叫M就叫B9，B7，就给大家一个例子，就是我们用了一个最傻的办法，也是最麻烦的办法，实现了一个预测精度也不是特别准的，这里真的做了一个什么事能够做一个手写算式，但这个是支持的力度比较小，能支持加减乘除能支持括号，然后，我们来介绍一下大概起。

首先第一步，你想支持的时候我们我们MNIST的是吗，0到9，你没有data是没有任何意义的，你想扩展的话，你必须收集足够的data，你要训练模型，因为你的模型就不是一个十分的问题了，对加减乘除加了一个两个括号其实就16分类的模型了。然后，你还怎么去给他最后去运行起来，这是第三步。那我们都有一个同事比较好，他自己做了一个这个PHONE插件挺好做的，就是有一个左边的小三角直接拿手写，假如你保存这样的话，你可以收集好多的公式自己存自己存data对这个那个都有了吧，这就是加号的然后，第一个就是你自己手写，然后但是有一个问题就是零到九你编了。然后后面这个加减乘除怎么编号，所以我们也没有办法只好从十开始编，所以你这个你match就不太好match，你只能变，然后就弄一堆，然后输过来之后，手写了加号，然后第二个方式就是什么你不想手写，其实特别这个有名的一个叫CARGO的一个这个深度学习的一个竞赛比赛里面，有一些这个例子就是它的外形的MAP对象散了他自己提供一个。所以，在这个网上就能看到他不光提供，包括什么那种，连乘，求和，什么之类的各种都有，然后这些都有所以公开的一些数据及还有从网上扒一些数据都可以这个能够收集数据的，然后，收集收集数据之后，你要怎么办，你要做手写算式吧，那时候像是不像是这个字图样怎么好识别了，所以咱们首先你什么你要拆分你怎么知道他哪个是一个字，哪个是个字符，哪些是一个数字，那些是那个符号运算符，所以你要进行一些拆分，所以这个超越过程就比较费劲了，这个就不是深度学习的就是领域了，但是你要是想一个算法怎么去拆。 这些你怎么拆，然后你拆完之后还要识别出来的预算，怎么求，所以这个时候也算是这个是个比较难的，我们对他是他除了训练，其实你训练，这些识别服务其实比较简单，你找手机号足够出一个可以训练，但是真正你要真正去识别它的时候，你这个，这个逻辑，这个是拆分的过程，其实也是很费劲的。

我们在北方将这一刻的时候，北航的学生们用了好多不同的方法实现了一些比较开根号，可能是外面的根号里面是个东西，然后不是整个是一个数，阿，刚才我们不是一个零到九吗，大家回去可以试试。你说写A，你看到就识别出了什么，他一定会在零到九之间，给你识别一个数的，可能会识别成一个零，这是很有可能的，因为他最后分类之后一定会给你分到这个十分类里面一个对吧。虽然这个东西根本就不是0，所以在这个时候你到底要怎么识别这些东西就是一个很大的一个问题了，然后再有就是什么，然后，怎么样去这个filter他。然后，怎么去进行转会做，然后把他几个分区约束符号是什么，然后第二个就是什么，在载入数据预处理的过程中，上次讲gan了对不对，这套我觉得会生成什么生成很多别的数据做数据增强，他能让这个数据更好使，那这个数据增强了这种方式其实有很多，比如说就是旋转，对吧，然后把它那个拉伸，然后移动对吧，清洗等等这些方式都能够那这些数字假如是一个旋转过的拉伸过的倾斜过的对吧，然后，那这样是不是还能够识别出来的，还是只能他所有的数据都是居中才能够识别，所以这也是一个问题，你怎么让你的识别度更好，然后再有就是这种，就是那个生成网络什么之类的好多算法，这些都不讲了。

一些这个字符就刚才那他的，这个dta的数据的收集，然后数据的增强，这数据部分处理就有很大的时间，光收集国内同事为了做这个，她连数据数据连那个整这个自己生成一些，他大概生成了几千个自己创能用的一些数据就是加减乘除什么括号加一块儿了几千个。挺费劲的，然后弄完了之后再training，之前，其实你还要做好多的工作。这个我我就刚才就说过了training之前你做工作比如说你要增加对吧，这个加减乘除，左括弧，右括弧。然后你要搁到划分一下，刚才那些DATA零到九都你也得怎么划分，然后你话说完了之后你可能还要read这些怎么把它打乱了，然后怎么能够让他都能够均匀地分配到不同的这个dataset里面，然后继续练，然后训练完了之后，设定就是这些都不用讲了，这些都是我们要设置的，然后这个也不讲这些框架的结构。

我们在这里我们最上一层，然后底下这些都是什么，大家可以自行了解，这个我会发给大家，然后这样子的话你设计的时候，那这些前面这些你都去了解了之后再才能知道你要怎么设计，这个当时我忘了删，那个第一个就是什么，我们怎么样计算，我怎么样把这个东西划分出来，第二个就是我怎么样去计算，其实我们对这两个大问题，第一个你划分了，但有可能预测不准比如走高，算了算不出来，所以这个有很多种方式，那么这里面我们用了一个特别特别 简单然后特别的，那个运算量可能稍微有点大的一种方式就是什么，我们看不有个四吗，对，这是一个四个笔划这个词在这里面这个笔画是这样的，那我们会把这些笔画到底怎么能够确定就是一个字母就是一个数字，我们有四加上五写了这么长就很确定的，他一般我们按照这个方式就是你看这个四个第一笔貌似在起来之前我都要存一下，他到底是这这个笔画的历史，这个轨迹什么样的笔记什么，然后所以你写完这个的时候就写了一个黄的，因为发现它映射到一个平面时候，这个四个这个绿色比红色笔记这个紫色笔记，其实映射到这个平面这个数的这个黄色笔记印象要这个平面对吧，他们之间是有交集的，你同一笔画里面的基本上是有交集的，你鼠标抬起来的时候你再写第二笔，它最后成了这个字的时候，最后他有交集的。 哪个有交集的笔画，我编好顺序，所以我给组合起来就是一个字符，那这个我也是写了第一笔是这个第二笔是这个他也是有交集的，所以这样组合起来，这两句话就是我的四跟五之间的一看比较急在中间这个空白，这时候就把它拆分开了，所以这个过程其实就是大家可以集思广益，这是思考题，还有什么别的办法能够把它弄得更好，对我们大概讲的就是这个字就是一个特别LOW的一个办法就是特别土，所以就六加三除以二就做了一个什么事儿，这个笔画的处理就是这样处理二把它拆开了对吧，所以第一步怎么样拆分这些计划第二步计算了，事实告诉大家，这个模型算这个，因为我们的第一个比较少，第二个，就是我们实在是这个也是有一些问题，算不出来，然后这是第二个是如何训练的问题，然后我就先给大家展示一下这个是怎么搞的。纯粹观摩，我看看能不能跑。

然后还有就是想办法改变我们算法提出模型的精确度，第二就是什么，我们还能还要想要扩充一下他，刚才我们只能算加减乘除，对吧，那么，假如说分数的我怎么去识别一个上下结构，中间分数的，然后我怎么去识别一个指数，我怎么识别一个根号，这些怎么样去划分，刚才像我们那种把它就是求个PROJECT，这种球它的映射这种肯定是不行的了，那在这里面有哪些方法去做，就这些事业思考，但是我们在北航的时候有些学生，他们就能够识别出这种分指数能识别出分数，他们就是怎么把这一块儿拆成两部分，就是上下结构拆了部分看了一部分这个这个分号，然后，他就先去别处中间那个分号，然后把分号以上，这个数据不是有这个坐标么坐标的上面那部分就是分母分子下面那部分就是分母，然后他去识别，然后这个也是就是别他最低线什么之类的，反正各种方法，大家可以去想，这是这个我们更多的一些思考的问题，然后我也不留什么思考题了，对它是怎么识别不合法，你怎么知道这些数字组合起来是这个东西要怎么识别这个一些不同的一些结构的，复杂的表达式结构等等，这个可以做一个思考。其实在我们这个手写字体识别的领域，很多研究的这个这个方向，只不过现在好像就没就是不知道大家有兴趣去研究这些太简单了，可能。但对我来说我觉得还是挺复杂的，讲具体识别这种分数手写的复杂的。识别的机器写出来其实是比较好，比较容易的，这手写的这种就比较困难，所以，这个手写的这个主要是什么，我们想知道他的意义在哪里，他的应用在哪里，如果能找到一个好的应用就会引发更多的人来研究，如果这个东西我们觉得我们不需要书写这些东西，多人在想什么，为什么我会有手写自己研究这样一个一个领域，其实像这样比如说人的写了一堆这种字怎么样把它跟打印版，然后，整个就是能够show给大家的时候，你识别这个他给你弄全都是正规的方式，然后出来了好多人熟悉一些公式，他想最后变成排版的，那可能会有些应用，但是这个就很难，还有这个作业帮什么，数学作业全对的要做帮他能够检查数学作业，大家检验那块就是拍照的。但他那个检查内部加减乘除，他能检查这么深的，对吧，而且我们这个地方识别的他那个，那个那个还是很快的，我觉得速度还挺快的，对当时所以我们觉得真的不知道这个对这个作业方式，百度起来研制研究的是不是百度的，什么反正后来小学的作业小学的那个作业帮小学的战术，所以我们看到对他要如果有这种场景，我们才能激发人去研究他没有用场景可能大家都不研究了。

## 24

用户在前端我们当时写了一个程序，在微信上，然后用户前端上传一个图片后端的这种进行中处理，然后处理完了就生成一个下联，然后合成一个图片返回给用户生成一个AI对联，然后在这里面，机器翻译等等这些过程，其实都可以用深度学习，然后一来就给大家介绍这些都干了什么重新给大家讲讲效果，比如说他首先要上传一个图片，然后上传上去，然后写个提交。然后提交然后做一堆处理处理完了就成这个样子，空气清新绿什么医嘱须怀淡泊心安，最后，然后就可以P个图合成一起成了这个样子，这就是这个AI对联儿自动生成的一个过程。我们所有的上联
在网上搜集的数据，下联都是自动机器生成的，自然语言处理的一些模型这个，所以我说比较复杂的就不用管这个为什么做一个案例，其实他他适合于教育大家也就意思意思听听就得了。

案例教学特点就是什么，第一个就是我们可以github收集公开的数据集，我们找了一个70万个对联的一个数据集，然后还有，就是有很多古诗唐诗宋词，就是这些用户们跟真的是可能收集这个对联唐诗宋词元曲什么的，全都整，然后，所以，你数据收集的时候，你可以在网上找到很多，我们就用了一个我们研究院自己收集过10万个，然后在这个网上还有一些，然后整合在一起，第二个数据处理那预处理的过程，我们说AI完整开发流程，你肯定要收集完数据，还有预处理，再深入学习NLP里面就是自然语言处理的理念，这些数据是需要一些预处理的，至少你的声音词了，因为在语言处理NLP做机器翻译，结果对联生成相当于机器翻译，中文翻英文，你也可以上来翻下联了，反正就是一个字儿对一个字。第三个就是构建模型，这个模型怎么构建就要深入学习的一些知识了，比如说我们这个会员系统里，我们用了微软定制化服务。这些都是那个目标检测的一些算法，就有很多对于目标检测许多这个现在比较好的算法，这些都是不同的算法，大家可以回去自己看这个单词带走，也可以发给大家，然后再有模型。可以本地调试，可以在平台优化可以在NI上进行优化这个NI下次送老师可能会讲派可能再送一回讲具体是什么，我给大家简单介绍一下吧，这个派什么是一个资源调度平台，你可以本机可能只有一个GPU，你本地没有GPU， 那我们就开启了云服务，你可以同时调度好多个这个，你可以通知调度好大台机器新型分布式并行训练那么做了一个这样的资源调度的训练的一个平台叫PAI，就是我们进行优化的时候，我们发现之前给他讲的例子都是什么的，大家都问你为什么选这个参数了，为什么选32，为什么就第一个128第二个32对吧，大家都有好多的这个问题，那其实这些都是调仓的过程，这个NI自动调参叫什么，就是深度学习，深度神经网络智能，就是什么，就是帮助你自动调参，他可以设置很多他有很多的算法能够帮助你在各种算法，各种就是深入学习的一些，超参之间进行自动的调整，帮你训练还是新版本。你每一种不同的参数，最后得的结果怎么样结果的对比有各种指标的衡量等等，这也是我们组的一个东西，然后这个也是比较复杂，下一次会讲这些都很复杂，我在这里都不说了。

模型的应用，所以你看我们完整的开发流程什么什么数据处理收集到处理，构建模型训练，训练完应用，最后一步用的时候你前面这些东西没有用，对吧，你现在干什么，你不能用，所以怎么把它用起来是一个过程，对这种一个完整的AI开发流程，每一步其实都费劲，那我们为什么要开发这个对联系统，就好玩有意思，然后大家可能都想用，然后在微信朋友圈里面，可能就那个，就是大家喜欢，那种受刺激，喜欢自己的文学素养的可能就喜欢这三个图的，然后自动帮你生成这点虽然现在我效果也不太好，那个我现在放在github那个是老版本，它的效果比较差，然后我们现在正在改进的是一个新版本，但效果明显的提升，但是我没有把它放上来，等着回头，我们改进好了，把代码再整理一下，可能我们就会再放到这个13里，所以以后等我弄好了再跟大家说，然后大家可以来看，然后我要把对你写的更清晰，大家知道怎么去自己来生成一个对联，这是特点，也不讲了，这时见我就说这个PAI平台就是这样，这是我截了一个图，这个图这个PAD273个CPU弄得在我们公司的一个机器上营运 99%了就等每次报完大家申请不上机器就是这种状态，只有这批有276个，然后273个都在用，就是你这些都能看到很多的信息MEMORY占用多少CPU资源是多少，都能查到。这个我们有没有显示出来，我们每一个提交了一个照相的时候照的怎么样，然后这个案例分析，然后这个案例是怎么能具体怎么到技术细节了，第一个就是我们要收集数据，这个我给大家给他的网址就那70万。对联，其实吧，这个数据并不大，你要想训练一个好的这种这种网络你必须要数量够多，然后质量也够好，在这里要删一些质量不好的，剩下的可能，就是也不见得就是特别多，几十万个数量真是不多，这70万个数据，然后在这里面就可以下载。已经完成了这个操作，他给的这个例子就已经空格隔开了，为什么，因为我们生成字表统计，这里有多少个汉字，因为我们生成对联的意思，NLP基本上都会用CMCC模型就是那种RNN的模型，那他就是什么，一个字推升另一个字对吧，一个输出输入对应一个输出一个对输入对的书，所以哪知道上一个字根下一个字是哪个对应的，你要知道这些字都是什么，然后生字表，然后我们其实现在改进用两个模型，全都能够生成我们的对联系统，然后质量差不多，然后这里面我给大家介绍的就是tensoft这一个，这一个模型，然后进行训练，这是身份训练数据的那个代码，这是一个库，所以找一个接口就可以了，然后模型，就要定义定义这个模型，我这个问题是什么，然后，我看到下载什么内容是什么，这些参数全都是要生成模型用到什么参数，大家也都可以知道就知道。
案例需要这些东西就知道多复杂，然后，就可以从里面选那在机器翻译也比较好的模型穿梭模型，也可以了解一下你可能别人不知道，但是你可以回去了解一些比较经典的一些东西。是对大家绝对是有好处的，在深度学习里面除了CNN这个常用的一个框架，对于一NIGHT处理非常好，但还有一种方式，一个于框架叫RNN，大家可能都知道，因为那个虽然好，但是他不能够处理这种时序的问题，他对比如说你要有时间概念来处理的问题，比如说什么叫时间概念，几个特简单例子大都喜欢的我今天迟到了，然后老师批批评今天迟到了，老师批评了啥，我们人来看都知道我，那机器，如果你让他在这里去补全，他怎么知道是我。这就跟时间有关系的前头有一个我对吧，但是，因为这个我离她距离太远了，所以可能识别不到。就是RNN最基础的模型的时候，还有一个问题就是为什么要用SPM，然后那个生成一些新的模型就是长短他能够识别一些。那个就是距离太远的这些词，他可能也能够识别然后，他可能识别不了那么远的距离的一些含义，然后后来又改进改进机制，可能大家都能够就是都听过这些词，
已知ESPM什么GRU这些东西还是有一些缺陷的，然后就是什么，其实我们自己人来看的时候，我们肯定知道这个我的优先级最低，这个权重高的，最后一看这就得批评了我，但是机器的时候它自己识别不出来，机制就什么就模仿人去您的关注点。注一些特定的词，然后，就把这些字重复着不同的值，所以加了这样的一个机制，大家在之前的其他别的还加了给他什么之类，里面加了GET，然后变成什么，这些都都不解释了，然后他就会加了一个机制，所以现在大家去了解的话，大家可以了解一下。网上好多特别简单的说明了干了什么的。那这个是什么，这是语言模型，要解决一个补全的问题，还有个什么，就机器翻译他解决是这个对吧，ILOVE YOU， 怎么变成LOVEYOU的时候怎么变成了就变成我爱你，这个东西对吧，一个字一个字翻译下去，只要翻译模型，然后一般怎么翻译模型，大家都会用SEQUENCETOCONCE这个经典的模型，所以大家可以了解一下什么是CQCONCE什么是LANGUAGEMODEL，其实有一个特别经典的一个东西就是怎么样处理这个LANGUAGEMODEL其实是需要什么，其实需要编码的，然后你的上面和下面怎么去编码，然后让大家机器能够理解你这个编码就是解码出来的时候就得是这个这个东西，所以说涉及到了一个MODEL里面的一个东西，，所有的单词转化成什么转化成WIFIVICTOR就讲向量，向量比较相关度吧，距离就可能能表示他什么相关，两个向量越近的时候，那他们距离其实就越越近，COFFEE距离越小吧，这个两个向量的距离越近，它的相识度高，所以这样的一个方式，怎么样转换，然后有好多那个算法，虽然最常用的算法，对大家自己看，叫那个cbow。 就是一些算法，这些这些东西具体是啥拿给自行研究，反正就是用了很多种方法帮助你把这个东西做最好，所以大家可以回去，要想了解NLP相关的东西，自然语言处理的东西，那大家可以先看从最基础的开始，我给大家解释一下，因为实在这个太费劲了，是吧，然后弄点简单的来简单的就是你先了解一下什么是RNN，一个循环神经网络怎么搞的，然后对吧，你就可以先搞一下，然后，包括成多个的时候是怎么样输出输入。然后，对吧，然后就是这个输出转到的这个输入的，然后就走了，他就等价于他了之类的，然后反正你就先了解RNN最基础的这些东西。了解完了之后，那最基础的时候，它具有一些改进版本最原始安全问题，然后他就加了LSTM，这个解决了很多的问题，但是还有一些问题解决不了，后来又一次又又在那儿研究LSTM还有发展出了好多就引进了好多的算法，但是这个LSTM还是很经典的那现在好多地方都在用。attention机制，trueform这个模型他在做自然语言处理的这个机器翻译的里面，他就用了tensoft的机制作了模型，然后这个模型就是取得非常好的效果，所以现在一般情况下，大家做自然语言处理。提出分布式表达这个概念，那怎么做分布式表达。

## 25

我到底怎么表示这个字？以前的时候，我们做开始的时候什么表示，比如说我想训练一个HelloWord的，然后你出个HELLO，比如说HE对吧，不小心费劲，然后L怎么表示，这个HEL，后来发现什么，这不是一个两个，三个四个字吗，对吧，那我怎么表示，H我这表示什么11000，E那就表示什么0100，L0010，O就是0001，这样的一个表示方法，然后你要最后做这个的时候，你给他输的时候你经过incoding，对，这个机子还有一个叫什么ecode的机制，这个也可以大家了解一下。

这个怎么编码的解码，他这个编码技术就是把这个一个词在输入的时候先别马上一堆，然后解码的时候就把这些解成另一个意思，就是做了一个翻译的过程，那这时候就是一种编码，这种变化很大的缺点，就是如果你自负非常多的时候，你这个维度非常大，你知道你很费劲，而且你好多都是零，然后，后来他就更新了好多别的编码方式，到最后现在最常用的编码的就是那个表达DISTRIBUTION分布式表达的方式，刚才我说那个，那个例子，大家都可以去了解一下，然后这几个概念，就是CNN里面比较常见的几个概念，大家就是就是怎么说，如果你就是什么都不懂，然后你知道那几个别人说的时候你也能够听两句，但是能够听两句那种状态。

然后这个是我们的背景知识，然后我们今天用的这个模型就是的trunsform模型做这个训练，那个FACEBOOK也出了一个LOGO的一个一个东西，那那那里面，我们用的是什么，是CNN就是卷积神经网络，就是普通话都能训练，只不过大家现在，就是机器翻译，大家都喜欢用传统方法效果比较好，背景知识讲了这么多，后面都可以略过，然后首先第一个，我们做了一个什么，刚才我们说了你上传一个图像对吧，你现在的图像做标注，你得照着图上说的什么，你就能找跟这个图片相关的一些对联儿，反正你们对着你的头像没有关系，没有用。
我一直没有因为我一直没有找到这个做这个的，我是什么情况，我一直都没找到就是做这个的，这个人，我其实，就是我们都在一个研究院，我没去问人家觉得不好意思，就是我真的特别想了解，我觉得他这做图像标注这个算法还是做得很好的，他是那个网页儿写的是他用了很多种不同的算法用最非常方案，最先进的算法就做的到底是什么算法，不知道，但是他标注起来，其实我就在猜想那你说你给了一个图相你说，你怎么标注它，比如说这个图像里面有一堆一个山有很多树民你就岛屿有海洋天空云彩有鸟，那你怎么标注这些信息，我们接着做分类，我们知道对吧，做分类就一个图就一个表情，对吧，那你这些图的多个标签。

你怎么搞，有很多问题，第一个目标检测对不对，你得知道检测出来哪个是物体的，好多不同的检测出来的物体，对上次就说画框的，大家崩溃了，更何况你还得检测出物体，并且把框对，然后你要怎么检测出来这个物体画的框框，应该检测出来，然后你想做出的图像里好多个物体都能分开，你也知道这某一个物体在这个图像中占的权重是多大，他有的可能那种不像有的可能是次要的，对，然后，你还得把它分类标志出来这个东西是啥，你把它就是检测出来不行，你还得分类，所以我觉得至少他都有图像检测图像分类两项我自己瞎猜的，因为这K就一个API调用大家，这就调动了一句话，你给一个API地址，然后把你的图像传上去就这么一句话API调用它就能给你返回所有的TAG就是，所以对于在这个图像里面标注的东西放到CONFiscience，就是他的知心度就是他到底这个知心度可靠性多高，他返回了一堆DIS这个这里没有想，不用，就是这些TAG的描述是什么，然后图像标准的算法，还有一些就是NLTK的算法HK非常好的一个库，大家可以回去研究一下给大家举个例子，那图像标注好了之后就该得到的图像相识度太高了，选出来之后，怎么办，我标注出来的东西怎么飞机大鸟对你见哪个古诗里有飞机大鸟了之类， 高楼大厦什么的，所以那我怎么样跟对联去匹配，我因为我就要对联，我们为了方便了我们把上联都收集好的数据，让他自动生成下联，那你找一个什么飞机找来一个什么多啦A梦的图片对不上，所以对我们的要求是什么，第一个我们收集的上联尽可能的丰富，不仅有古诗能有热词可能有这个现代版的我们还得天涯论坛上看到好多人自己创作的，但是我没有版权，所以没法用，然后那个你就就没搞，那我们找这个70万个这个公开数据，他是古往今来的各种都有，有好玩的那些都有，然后这些相似度的匹配，那个你，你有的上联，我们把上联提供出来匹配的，但是，你怎么去匹配，我们传统的方法就可以用精确匹配目标各种匹配吧，就是你匹配一些就是字符串查找什么之类的那种方式，我们这个版本就是用的特别老的方法。
如果你拿精确匹配就是匹配不上，我们以前见了两级磁疗匹配单个字体配两个字三个字等等，那其实很难，所以在这里面深入学习的算法比传统方法好了很多，那个我们的那个性能提高了提高了很大一节，然后相似度配好了之后，你就可以根据你匹配的那个词，或者这个词，你去上联那里找那些图片，还有那些字，然后从里面选出一些好的来，这就是这就是对这个上联的问题了，那上联弄完了之后数据处理的时候怎么办，你还要做一个模型，这个模型是什么，就是我们的匹配好了之后你怎么办，你要把这个上联的数据进行模型设定，然后你得训练，训练好一个下联，然后训练好了之后，你要把这个模型保存下来，然后保存下来之后还要写一个程序去推理他，然后，你再开发一个应用，就是我们整个的一个过程，整个的过程。那我现在就给大家演示一下案例，但是如果你不看我的演示，你刚看着演练你光看这个，你可能跑不起来，所以，我跟大家来演练一下，大家就了解一下就得了，就是仅限于了解。以后，我们把这个更新的更好的时候，然后我们会写会写一个更详细的一个一个文档，大家一步一步都能跟着操作的，现在网上那个，大家可以看训练的过程是可以完全跟着操作的，这个模型推理的过程还不行，因为有些code还不能够开源出去，目前在整理整理，主要是怕一些LICENSE问题会引起问题。
 给大家演示一下。