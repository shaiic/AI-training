# 微软-仪电人工智能高阶人才培训学习心得之八：501课程-计算机视觉专题
## 作者：刘恒


学习课程已过半，今天微软的大牛们带我们进入了计算机视觉专题

### 计算机的'看'
>- 让计算机'看'是一个不小的壮举。为了让机器像人或动物一样真正地观察世界，它依赖于计算机视觉和图像识别。
>- 计算机视觉是条形码扫描仪能够“看到”UPC中的一堆条纹的能力。这也是Apple的Face ID可以判断出它的相机正在看的脸是否是你的。基本上，只要机器处理原始视觉输入（例如JPEG文件或摄像机馈送），它就会使用计算机视觉来理解它所看到的内容。一般来讲计算机视觉视为处理眼睛接收到的信息的人类大脑的一部分 - 而不是眼睛本身。
>- 从人工智能的角度来看，计算机视觉最有趣的用途之一是图像识别，它使机器能够解释通过计算机视觉接收的输入并对其“看到”进行分类。


### GAN算法
>- GAN生成式对抗网络（Generative Adversarial Networks ）是一种深度学习模型，是近年来复杂分布上无监督学习最具有前景的方法之一。
>- GAN生成式对抗网络的模型至少包括两个模块：G模型－生成模型（Generative Model）和D模型－判别模型（Discriminative Model）。两者互相博弈学习产生相当好的输出结果。GAN 理论中，并不要求G、D模型都是神经网络，只需要是能拟合相应生成和判别的函数即可。但实际应用中一般均使用深度神经网络作为G、D模型。

#### GAN算法原理
>- 假设有两个网络，分别为G（Generator）和D（Discriminator）,G是一个生成图片的网络，它接收一个随机的噪声z，通过这个噪声生成图片，记做G（z）;D是一个判别网络，判别一张图片是不是“真实的”。它的输入参数是x，x代表一张图片，输出D（x）代表x为真实图片的概率，如果为1，就代表100％是真实的图片，而输出为0，就代表不可能是真实的图片。
>- 在最理想的状态下，G可以生成足以“以假乱真”的图片G（z）。对于D来说，它难以判定G生成的图片究竟是不是真实的，因此D（G（z）） ＝ 0．5,这样目的就达成了：得到了一个生成式的模型G，它可以用来生成图片。
>- 在训练过程中，生成网络G的目标就是尽量生成真实的图片去欺骗判别网络D。而判别网络D的目标就是尽量把G生成的图片和真实的图片分别开来。这样，G和D构成了一个动态的“博弈过程”。

#### GAN算法优点&缺点
#### 优点
>- 1）使用了latent code，用以表达latent dimension、控制数据隐含关系等；
>- 2）数据会逐渐统一；
>- 3）不需要马尔可夫链；
>- 4）被认为可以生成最好的样本（不过没法鉴定“好”与“不好”）；
>- 5）只有反向传播被用来获得梯度，学习期间不需要推理；
>- 6）各种各样的功能可以被纳入到模型中；
>- 7）可以表示非常尖锐，甚至退化的分布。
#### 缺点
>- 1）Pg（x）没有显式表示；
>- 2）D在训练过程中必须与G同步良好；
>- 3）G不能被训练太多；
>- 4）波兹曼机必须在学习步骤之间保持最新。

#### GAN算法应用
>- GAN的应用范围较广，扩展性也强，可应用于图像生成、数据增强和图像处理等领域。
>- 1）图像生成：目前GAN最常使用的地方就是图像生成，如超分辨率任务，语义分割等。
>- 2）数据增强：用GAN生成的图像来做数据增强。主要解决的问题是a）对于小数据集，数据量不足，可以生成一些数据；b）用原始数据训练一个GAN，GAN生成的数据label不同类别。


## 卷积神经网络
>- 卷积神经网络是近年发展起来的，并引起广泛重视的一种高效识别方法，20世纪60年代，Hubel和Wiesel在研究猫脑皮层中用于局部敏感和方向选择的神经元时发现其独特的网络结构可以有效地降低反馈神经网络的复杂性，继而提出了卷积神经网络（Convolutional Neural Networks-简称CNN）。现在，CNN已经成为众多科学领域的研究热点之一，特别是在模式分类领域，由于该网络避免了对图像的复杂前期预处理，可以直接输入原始图像，因而得到了更为广泛的应用
>- 一般的，CNN的基本结构包括两层，其一为特征提取层，每个神经元的输入与前一层的局部接受域相连，并提取该局部的特征。一旦该局部特征被提取后，它与其它特征间的位置关系也随之确定下来；其二是特征映射层，网络的每个计算层由多个特征映射组成，每个特征映射是一个平面，平面上所有神经元的权值相等。特征映射结构采用影响函数核小的sigmoid函数作为卷积网络的激活函数，使得特征映射具有位移不变性。此外，由于一个映射面上的神经元共享权值，因而减少了网络自由参数的个数。卷积神经网络中的每一个卷积层都紧跟着一个用来求局部平均与二次提取的计算层，这种特有的两次特征提取结构减小了特征分辨率。

### 案例
>- 假设给定一张图（可能是字母X或者字母O），通过CNN即可识别出是X还是O，如下图所示，那怎么做到的呢
![1.png](https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202515631-1056461501.png)

>- 如果采用经典的神经网络模型，则需要读取整幅图像作为神经网络模型的输入（即全连接的方式），当图像的尺寸越大时，其连接的参数将变得很多，从而导致计算量非常大。
　　而我们人类对外界的认知一般是从局部到全局，先对局部有感知的认识，再逐步对全体有认知，这是人类的认识模式。在图像中的空间联系也是类似，局部范围内的像素之间联系较为紧密，而距离较远的像素则相关性较弱。因而，每个神经元其实没有必要对全局图像进行感知，只需要对局部进行感知，然后在更高层将局部的信息综合起来就得到了全局的信息。这种模式就是卷积神经网络中降低参数数目的重要神器：局部感受野。
![2.png](https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202559906-1527391226.png)

>- 我们的目标是对于各种形态变化的X和O，都能通过CNN准确地识别出来，这就涉及到应该如何有效地提取特征，作为识别的关键因子。
　　回想前面讲到的“局部感受野”模式，对于CNN来说，它是一小块一小块地来进行比对，在两幅图像中大致相同的位置找到一些粗糙的特征（小块图像）进行匹配，相比起传统的整幅图逐一比对的方式，CNN的这种小块匹配方式能够更好的比较两幅图像之间的相似性。如下图以字母X为例：
![3.png](https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202702561-93616180.png)

>- 假如以像素值"1"代表白色，像素值"-1"代表黑色，则字母X的三个重要特征如下：
![4.png](https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202719374-1192154873.png)

> 那么这些特征又是怎么进行匹配计算呢？

### 卷积
> 当给定一张新图时，CNN并不能准确地知道这些特征到底要匹配原图的哪些部分，所以它会在原图中把每一个可能的位置都进行尝试，相当于把这个feature（特征）变成了一个过滤器。这个用来匹配的过程就被称为卷积操作，这也是卷积神经网络名字的由来,卷积的操作如下图所示：
![5.png](https://img2018.cnblogs.com/blog/1226410/201810/1226410-20181009202815705-1130979104.gif)

> 以此类推，对三个特征图像不断地重复着上述过程，通过每一个feature（特征）的卷积操作，会得到一个新的二维数组，称之为feature map。其中的值，越接近1表示对应位置和feature的匹配越完整，越是接近-1，表示对应位置和feature的反面匹配越完整，而值接近0的表示对应位置没有任何匹配或者说没有什么关联。如下图所示：
![6.png](https://static.oschina.net/uploads/space/2018/0210/003257_dZEn_876354.png)

### 池化
> 为了有效地减少计算量，CNN使用的另一个有效的工具被称为“池化(Pooling)”。池化就是将输入图像进行缩小，减少像素信息，只保留重要信息。
> 池化的操作也很简单，通常情况下，池化区域是2*2大小，然后按一定规则转换成相应的值，例如取这个池化区域内的最大值（max-pooling）、平均值（mean-pooling）等，以这个值作为结果的像素值。

> 下图显示了左上角2*2池化区域的max-pooling结果，取该区域的最大值max(0.77,-0.11,-0.11,1.00)，作为池化后的结果，如下图：
![7.png](https://static.oschina.net/uploads/space/2018/0210/003312_A4YP_876354.png)

> 对所有的feature map执行同样的操作，结果如下：
![7.png](https://static.oschina.net/uploads/space/2018/0210/003329_XCiq_876354.png)

> 最大池化（max-pooling）保留了每一小块内的最大值，也就是相当于保留了这一块最佳的匹配结果（因为值越接近1表示匹配越好）。也就是说，它不会具体关注窗口内到底是哪一个地方匹配了，而只关注是不是有某个地方匹配上了。通过加入池化层，图像缩小了，能很大程度上减少计算量，降低机器负载。

## MNIST
> 大多数示例使用手写数字的MNIST数据集。 该数据集包含60,000个用于培训的示例和10,000个用于测试的示例。 这些数字已经标准化，并以固定大小的图像（28x28像素）为中心，其值为0到1.为简单起见，每个图像都被展平并转换为784个特征（28 * 28）的一维 numpy数组）。这在机器学习领域是相当于“Hello World”的入门示例。

> 这在机器学习领域中被称为有监督学习，因为我们已经知道图像预测所应该得出的正确答案。训练集能起到监督和指导的作用，在神经网络预测错误时予以纠正



# 关于微软-仪电人工智能创新院
微软-仪电人工智能创新院将由微软和仪电共同运营和管理，致力于为微软和仪电在人工智能方面的联合研究活动和项目提供支持，为当地企业提供基于微软技术的人工智能研发平台服务和培训服务。

# 关于培训
微软和仪电共同打造的微人工智能高阶人才培训第一期培训班由创新院运营，历时三个月，授课老师包括来自微软和上海仪电的多位专家，内容涵盖人工智能导论、数学基础、深度学习、应用实例等课程，以及关于强化学习、自然语言处理、计算机视觉等热门方向的专题研讨会，希望帮助学员掌握人工智能的理论与实践，培养具备前瞻视野和实践能力的创新型人才。

更多信息，请关注微信公众号
![二维码](./image/barcode.jpg)