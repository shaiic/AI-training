# 微软-仪电人工智能高阶人才培训学习心得之一：201课程-线性代数 概率统计

## 作者：王德扬（上海仪电人工智能创新院有限公司）

# 线性代数

周老师首先解释了线性代收里面的线性。线性含义是 对于任意$\alpha$ 有 $\alpha f(x)=f(\alpha x) $ 。由于线性函数易于理解，易于处理。适合作为代数的基础。

周老师的线性代数由向量开始，自始至终都有图像跟随。向量就可以用图像表示为有长度有方向的箭头。

## 向量

在平面直角坐标系中，二维向量与坐标点有一一对应的关系。可以由坐标来确定向量，并计算向量的各种特征。比如计算向量的方向与长度。对于坐标点$ (x,y) $ ，其方向为$ argtan(y/x) $ 其长度为 $ \sqrt{(x^{2}+y^{2})}$ 。

关于方向，方向定义没有歧义，区别在于是弧度制还是角度制。numpy默认是弧度制，可以通过`math.degrees()`来将弧度制转化为角度制。

关于长度，对于长度而言，其定义是有多种的，数学上称之为范数，可以用`np.linalg.norm(v)`来计算各种各种定义下对应的范数。最常见的范数是欧式范数，`np.linalg.norm(v)`在不带参数的情况下计算的就是欧式范数。对于矩阵而言，也采取相同的欧式范数计算方法，也就是先平方再加和再取开根号的形式来计算范数。

向量乘法：

- 标量乘

  对应于伸缩，计算方式就是numpy对应的扩散模式，直接用`*`乘即可

- 点积

  对应于物理世界的做功，结果为标量。计算方式为`np.dot(v1,v2)`

- 叉积

  对应于物理世界的转动惯量，结果为矢量。计算方式为`np.cross()`


## 矩阵

- 矩阵乘法

  矩阵乘法没有叉积，只有标量乘与点积。写法与向量相同，需要注意的点有

  -- 矩阵需要形状匹配

  -- 矩阵乘法仅有结合律，没有交换律。所以矩阵是群最方便的表示。

- 变换，特征向量和特征值
  补充 沿着x轴翻转的矩阵为$ \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix} $

- 特征分解

  特征分解类比于泰勒展开，傅里叶展开。先将原有向量变换到新的空间，然后在新的空间里对向量做变换。使用新空间的原因在于在新空间可以更有效的提取特征，比如泰勒展开可以计算截断误差；傅里叶展开可以进行滤波处理，留取我们想要的高频或低频信息；特征分解可以用来提取变换的主成分，有利于抓住矩阵的主要特征。


# Game of life

## 问题描述
GOF是一个二维空间上的生灭问题。对于任意整点$ (i,j) \;i,j \in Z^{+} $ 若其自身是生的状态，而且有2或3个生状态的邻居(邻居是其周围的8个整点)，则此点在下个时刻是生。若其自身是灭的状态，而且有且仅有3个生状态的邻居，则其下个时刻是生。其他情况此整点的下个状态都是灭。

## 基本条件
我们添加三个条件，以便于使用numpy求解此问题。
- 仅考虑有限空间内的生灭问题
- 有限空间是正方形
- 正方形边界上的整点自始至终都是灭的状态

## 基本思路
面对这个问题，一个自然的想法是将正方形内部(非边界)的点逐一挑出来，计算其周围邻居的状态，得到自身下一刻的生灭状态，然后放到下一时刻的生灭状态表中。从计算的时间空间复杂度角度考虑，此方法的时空复杂度都是O(N),是个不错的算法。

不过在实际计算中，此方法非常费时。原因在于对于python而言，寻址，取值操作都需要花费大量时间。这些时间并没有统计到到时间复杂度计算里。所以理论上的好算法在实际运行中并没有得到好的效率。

## 优化方法
解决办法有两种：第一种是更换语言，使用更接近计算时空复杂度计算的语言来编写程序，比如c语言。第二种是使用优化过的工具来实现计算邻居状态，numpy提供了这种方法，其思想为整块计算。通过整块计算，numpy可以预先知道待计算内容的数据类型，空间排布。也就可以使用优化的方法来加速计算。

### 砖方法
因为邻居矩阵的方向有8个,所以我们把每个方向上的邻居数都当成一个矩阵，这样我们可以得到8个矩阵；然后8个矩阵求和，就得到了邻居数。通过邻居数和自身生灭状态，就可以判断出下一时刻的生灭状态。

具体计算邻居矩阵的方法是对于上下左右4个方向，可以将一列切边，然后在对面补上空边，这样就计算出了一个邻居矩阵。对于斜着的方向，现在一个方向做切边补边，再在另一个方向做同样操作。便可得到斜着的邻居矩阵。

这样一共生成8个临时变量，24次整体操作。从时间结果看，较基本方法有较大提高。

### 玉方法
思路类似于砖方法，但在邻居矩阵的生成上有更巧妙的办法。若我们仅考虑内部大小，不考虑边，则可以不用生成新变量，直接用原变量切片的view就可以表示邻居矩阵。这样就降低了空间复杂度。由于在原位计算，cpu缓存命中率也会有所提升，提高运算效率。此方法运算时间又较砖方法有较大提高


# 概率统计

## 偏度和峰度
偏度 偏度表征了分布中心位置与分布重心位置的差别。

峰度 峰度表征了分布尖锐程度。正态分布的峰度为3

## 异常值
例外是距离中值点太远的反常数据。例外总需要解释，

来源检测

数据错误：丢弃数据

数据无误：确认模型是否可处理

   可以处理: 接受例外

   不便处理: 排除例外


## 归一化
归一化使数据由绝对量变成相对量，统一了数据范围，使各个数据平权化，具有可比性。
\begin{equation}Z = \frac{x - \mu}{\sigma}\end{equation}

## 最小二乘拟合
最小二乘拟合是无偏估计中最好的估计。对于某些极端情况，我们可以权衡无偏这个前提。

## 3块糖分给13个小朋友
提供一个新的解法，穷举法
思路是对于两块糖，分给n个小朋友，显然有n+1种分法
对于三块糖，可以简化为第一个小朋友m块，剩下两个小朋友分n-m块
则总分法为 (n+1) n (n-1) ... (n-m) ... 1 求和可得结论

## 用样本均值生成样本分布
由样本的均值，方差，分布等信息构造样本分布。可用于某些问题求近似解，比如蒙特卡洛方法。

# 关于微软-仪电人工智能创新院
微软-仪电人工智能创新院将由微软和仪电共同运营和管理，致力于为微软和仪电在人工智能方面的联合研究活动和项目提供支持，为当地企业提供基于微软技术的人工智能研发平台服务和培训服务。

# 关于培训
微软和仪电共同打造的微人工智能高阶人才培训第一期培训班由创新院运营，历时三个月，授课老师包括来自微软和上海仪电的多位专家，内容涵盖人工智能导论、数学基础、深度学习、应用实例等课程，以及关于强化学习、自然语言处理、计算机视觉等热门方向的专题研讨会，希望帮助学员掌握人工智能的理论与实践，培养具备前瞻视野和实践能力的创新型人才。

更多信息，请关注微信公众号
![二维码](./image/barcode.jpg)
