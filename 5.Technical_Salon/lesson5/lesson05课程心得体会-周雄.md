```
# 微软-仪电人工智能高阶人才培训(第一期）学习心得之五：深度学习-神经网络
## 作者：周雄（上海仪电人工智能创新院有限公司）

# 动手很重要
**For things I don't know how to build, I don't understand.**
**如果有个东西是我不能亲手搭建起来，那么我就不能理解它。 -- 美国物理学家理查德·费曼**

老师总结了神经网络学习由浅入深的9个步骤，本次课程老师带着我们从基础的概念，到推导公式，再到实际的代码练习，帮助我们了解到了神经网络的原理和基础用途。
1.基本概念
2.线性回归
3.线性分类
4.非线性回归
5.非线性分类
6.模型的推理与应用部署
7.深度神经网络
8.卷积神经网络
9.循环神经网络

# 神经网络的基本工作原理
神经元细胞的数学模型
![神经元细胞的数学模型](./image/神经元细胞的数学模型.png)
其中参数如下
输入 input
	x1,x2,x3
权重 weights
	w1,w2,w3
偏移 bias
	b
公式
	y=wx+b
激活函数activation
	A=a(Z)
如果不使用激活函数，我们的每一层输出只是承接了上一层输入函数的线性变换，无论神经网络有多少层，输出都是输入的线性组合。如果使用的话，激活函数给神经元引入了非线性的因素，使得神经网络可以逼近任何非线性函数，这样神经网络就可以应用到非线性模型中。
因此
激活函数是用来加入非线性因素的，解决线性模型所不能解决的问题。

# 神经网络的训练过程
训练流程
![训练过程](./image/TrainFlow.png)
总体来说，训练的过程就是通过不断的迭代和缩小计算值和样本值的差距，使得模型接近于训练的数据。
训练完成后，我们就可以使用训练的结果，带入真实的数据进行验证。

#神经网络的主要功能
神经网络并不是精确的，只是一个在误差范围内的近似值
神经网络并不是万能的，主要用于解决以下两种问题
1.拟合
2.分类

目前已经比较成熟的神经网络：
卷积神经网络 CNN (Convolutional Neural Networks)
	用于解决图像类的问题
循环神经网络 RNN (Recurrent Neural Networks)
	用于解决语言类的问题

神经网络三大概念：反向传播，梯度下降，损失函数。

反向传播和梯度下降是整个神经网络中的重要组成部分，是和误差函数/损失函数的概念分不开的。
损失函数的作用，就是计算神经网络每次迭代的前向计算结果与真实值的差距，从而指导下一步的训练向正确的方向进行。

#反向传播四大公式推导
著名的反向传播四大公式（其实没有特别明白）：

  $$\delta^{L} = \nabla_{a}C \odot \sigma_{'}(Z^L) \tag{80}$$
  $$\delta^{l} = ((W^{l + 1})^T\delta^{l+1})\odot\sigma_{'}(Z^l) \tag{81}$$
  $$\frac{\partial{C}}{\partial{b_j^l}} = \delta_j^l \tag{82}$$
  $$\frac{\partial{C}}{\partial{w_{jk}^{l}}} = a_k^{l-1}\delta_j^l \tag{83}$$

#线性回归
线性回归应该是在神经网络中最简单，最基础的内容了。
可用的一些方法
最小二乘法：数学解析
梯度下降法：逐渐逼近
神经网络法：本质上和梯度下降没区别，我的理解是通过结构化模块化的方式实现

# 关于
微软-仪电人工智能创新院
微软-仪电人工智能创新院将由微软和仪电共同运营和管理，致力于为微软和仪电在人工智能方面的联合研究活动和项目提供支持，为当地企业提供基于微软技术的人工智能研发平台服务和培训服务。

# 关于培训
微软和仪电共同打造的微人工智能高阶人才培训第一期培训班由创新院运营，历时三个月，授课老师包括来自微软和上海仪电的多位专家，内容涵盖人工智能导论、数学基础、深度学习、应用实例等课程，以及关于强化学习、自然语言处理、计算机视觉等热门方向的专题研讨会，希望帮助学员掌握人工智能的理论与实践，培养具备前瞻视野和实践能力的创新型人才。

更多信息，请关注微信公众号
![二维码](./image/barcode.jpg)
```