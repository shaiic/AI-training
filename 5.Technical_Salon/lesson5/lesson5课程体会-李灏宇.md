# 微软-仪电人工智能高阶人才培训(第一期）学习心得之一：***课程
## 作者：李灏宇（上海仪电人工智能创新院有限公司）

代码这个东西嘛，本来就是一个很枯燥的东西，但是呢，在这个世界上，有一群人，他们非常的喜欢搞事情，能把代码这个东西翻来覆去的玩出花儿来，让我们来看看下面的这副动图：
![](https://github.com/Yanyueyimeng/AI-training/blob/master/5.Technical_Salon/lesson5/image/Conways_game_of_life_breeder_animation.gif?raw=true)
（生命游戏示意图）
这是一幅John Conway‘s的生命演化游戏所展示的演化图样，你可能想象不到，如此变化多端又生生不息的景象，仅仅只需要4条规则：
•	当前细胞为存活状态时，当周围的存活细胞低于2个时（不包含2个），该细胞变成死亡状态。（模拟生命数量稀少）
•	当前细胞为存活状态时，当周围有2个或3个存活细胞时，该细胞保持原样。
•	当前细胞为存活状态时，当周围有超过3个存活细胞时，该细胞变成死亡状态。（模拟生命数量过多）
•	当前细胞为死亡状态时，当周围有3个存活细胞时，该细胞变成存活状态。（模拟繁殖）

在游戏的进行中，杂乱无序的细胞会逐渐演化出各种精致、有形的结构；这些结构往往有很好的对称性，而且每一代都在变化形状。一些形状已经锁定，不会逐代变化。有时，一些已经成形的结构会因为一些无序细胞的“入侵”而被破坏。但是形状和秩序经常能从杂乱中产生出来。
大家是不是觉得很有意思呢？当然程序员们也喜欢搞一些特定的初始状态来达到特定的图样：
![](https://github.com/Yanyueyimeng/AI-training/blob/master/5.Technical_Salon/lesson5/image/12.gif?raw=true)
![](https://github.com/Yanyueyimeng/AI-training/blob/master/5.Technical_Salon/lesson5/image/11.gif?raw=true)

这些生命游戏的图样可以用各种各样的程序语言来进行实现，这些实现的程序语言实现起来有的长，有的段，有的复杂，有的简单。我原本以为如此复杂的变化所需要的代码量应该也会比较大，直到我见到了下面的大神作品：
![](https://github.com/Yanyueyimeng/AI-training/blob/master/5.Technical_Salon/lesson5/image/1.png?raw=true)

如此复杂的程序，竟然就只有这短短的一行，我一直在想着，什么时候我也能够写出如此简练又功能强大的代码，什么时候我也能够用我的智慧来为人类文明的发展添上一点薪薪之火。

从5月底开始，我加入了一个程序员大神们云集的一个神秘学习班，在这个班级里，同学们从python开始学期，经历了数学基础，AI伦理等课程，现在进入了神经网络基础这门课程。

神经网络由基本的神经元组成，下图就是一个神经元的数学/计算模型，便于我们用程序来实现。
![](https://github.com/Yanyueyimeng/AI-training/blob/master/5.Technical_Salon/lesson5/image/NeuranCell.png?raw=true)

**输入 input**

(x1,x2,x3) 是外界输入信号，一般是一个训练数据样本的多个属性，比如，我们要预测一套房子的价格，那么在房屋价格数据样本中，x1可能代表了面积，x2可能代表地理位置，x3可能朝向。另外一个例子是，假设(x1,x2,x3)分别代表了(红,绿,蓝)三种颜色，而此神经元用于识别输入的信号是暖色还是冷色。

**权重 weights**

(w1,w2,w3) 是每个输入信号的权重值，以上面的 (x1,x2,x3) 的例子来说，x1的权重可能是0.92，x2的权重可能是0.2，x3的权重可能是0.03。当然权重值相加之后可以不是1。

**偏移 bias**

还有个b是怎么来的？一般的书或者博客上会告诉你那是因为$y=wx+b$，b是偏移值，使得直线能够沿Y轴上下移动。这是用结果来解释原因，并非b存在的真实原因。从生物学上解释，在脑神经细胞中，一定是输入信号的电平/电流大于某个临界值时，神经元细胞才会处于兴奋状态，这个b实际就是那个临界值。亦即当：

$$w1 \cdot x1 + w2 \cdot x2 + w3 \cdot x3 >= t$$

时，该神经元细胞才会兴奋。我们把t挪到等式左侧来，变成$(-t)$，然后把它写成b，变成了：

$$w1 \cdot x1 + w2 \cdot x2 + w3 \cdot x3 + b >= 0$$

于是b诞生了！

**求和计算 sum**

$$Z = w1 \cdot x1 + w2 \cdot x2 + w3 \cdot x3 + b = \sum_{i=1}^m(w_i \cdot x_i) + b$$

在上面的例子中m=3。我们把$w_i \cdot x_i$变成矩阵运算的话，就变成了：

$$Z = W \cdot X + b$$

**激活函数 activation**

求和之后，神经细胞已经处于兴奋状态了，已经决定要向下一个神经元传递信号了，但是要传递多强烈的信号，要由激活函数来确定：

$$A=a{(Z)}$$

如果激活函数是一个阶跃信号的话，那受不了啊，你会觉得脑子里总是一跳一跳的，像继电器开合一样咔咔乱响，所以一般激活函数都是有一个渐变的过程，也就是说是个曲线。

至此，一个神经元的工作过程就在电光火石般的一瞬间结束了。

上面的这段都是我复制黏贴的，因为我到现在都还在懵逼状态中，都在好好的体会课程精神的过程中，总结来说呢，神经网络方法就是模拟人类大脑中的神经细胞的活动方法来达到处理问题的过程，说句玩笑话，深层神经网络学习其实应该算是仿生学的一部分，通过学习人脑神经的运作来达到处理问题的目的。

当然啦，只有一层的神经网络是不行的啦，多层神经网络的叠加才能达到人工智能处理问题的目的。接下来我也不贴更多更枯燥的公式了，这只会让大家重新体会到被大学高数所支配的恐惧。

经过一些列严格的数学公式推倒以及一些神奇算法，我们的深层神经网络已经能够处理一些具体的问题，并对结果做出预测，怎么样，是不是已经有点AI的样子出来了，但是具体这个是怎么做到的呢？请关注人工智能创新院（云赛空间公众号）。期待接下来的更新，如果你有一定的数据及代码基础，也可以来报名参加人工智能高阶人才培训的课程，有微软亚太研究院大牛来给你授课，你也可以见到幽默风趣的我。

#关于微软-仪电人工智能创新院
微软-仪电人工智能创新院将由微软和仪电共同运营和管理，致力于为微软和仪电在人工智能方面的联合研究活动和项目提供支持，为当地企业提供基于微软技术的人工智能研发平台服务和培训服务。

# 关于培训
微软和仪电共同打造的微人工智能高阶人才培训第一期培训班由创新院运营，历时三个月，授课老师包括来自微软和上海仪电的多位专家，内容涵盖人工智能导论、数学基础、深度学习、应用实例等课程，以及关于强化学习、自然语言处理、计算机视觉等热门方向的专题研讨会，希望帮助学员掌握人工智能的理论与实践，培养具备前瞻视野和实践能力的创新型人才。

更多信息，请关注微信公众号
![二维码](./image/barcode.jpg)